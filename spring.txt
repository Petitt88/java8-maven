@Component
@Service
@Repository
@Controller
@RestController
@Scope
@Bean

@Valid
@ModelAttribute - this is used to add stuff to spring's model and it ultimately goes into the HttpServletRequest object after the handler executes
@SessionAttributes("key") - adds the value from the ModelMap that belongs to the specified key to the HttpSession object after the handler executes
@ResponseBody
@RequestBody
@PathParam
@Value - specify default value on properties. Can be arbirtary string or expression e.g. "#{systemProperties.myProp}"

@ControllerAdvice - it is typically used to define @ExceptionHandler, @InitBinder, and @ModelAttribute methods that apply to all @RequestMapping methods.
@ExceptionHandler
@ResponseStatus

@Cacheable - to use Spring's cache - implementations can be swapped

@Lazy - lazily initialze beans

@Import - Provides functionality equivalent to the <import/> element in Spring XML. Allows for importing @Configuration classes, ImportSelector and ImportBeanDefinitionRegistrar implementations, 
		  as well as regular component classes (as of 4.2; analogous to AnnotationConfigApplicationContext.register(java.lang.Class<?>...)).


org.springframework.beans.factory.Aware
Sometimes we need Spring Framework objects in our beans to perform some operations, 
for example reading ServletConfig and ServletContext parameters or to know the bean definitions loaded by the ApplicationContext. 
That’s why spring framework provides a bunch of *Aware interfaces that we can implement in our bean classes.

mvn -DskipTests=true clean install

spring.factories: a file that contains auto-configuration classes for everything. These are only included when certain
	conditions are met thanks to the @ConditionalOnClass annotation which is like the .NET #ifdef
	
https://github.com/spring-projects/spring-boot
https://github.com/spring-projects/spring-boot/tree/master/spring-boot-autoconfigure
	

Spring:
	- Dev tools: automatically restarts the server when any change happens to our source files (.java, .jsp) on the local classpath.
				 It is automatically disabled in production: when the app is started via the command line.

		- this is achieved by using 2 class loaders: 1 for the libs, maven dependencies which never change
													 1 for our source code which can change
		- in case of a change the lib classloader remains intact, whereas the source-file classloader is recreated. This ensures performance in a microservice world.
		
	- Actuator: provides monitoring capabilities that can be reached via http endpoints or via JMX

		- Endpoints Actuator endpoints allow you to monitor and interact with your application. 
		  Spring Boot includes a number of built-in endpoints and you can also add your own. 
		  For example the health endpoint provides basic application health information. 
		  Run up a basic application and look at /health (and see /mappings for a list of other HTTP endpoints).

		- Metrics Spring Boot Actuator includes a metrics service with “gauge” and “counter” support.
		  A “gauge” records a single value; and a “counter” records a delta (an increment or decrement). 
		  Metrics for all HTTP requests are automatically recorded, so if you hit the metrics endpoint should see a sensible response.

		- Audit Spring Boot Actuator has a flexible audit framework that will publish events to an AuditService. 
		  Once Spring Security is in play it automatically publishes authentication events by default. 
		  This can be very useful for reporting, and also to implement a lock-out policy based on authentication failures.

		- Process Monitoring In Spring Boot Actuator you can find ApplicationPidFileWriter which creates a file containing the 
		  application PID (by default in the application directory with a file name of application.pid).
		  
		  
		  
JDBC:
		// load the Driver Class
		Class.forName(props.getProperty("DB_DRIVER_CLASS"));

		// create the connection now
		con = DriverManager.getConnection(props.getProperty("DB_URL"),
				props.getProperty("DB_USERNAME"),
				props.getProperty("DB_PASSWORD"));
	
	
JDBC DataSource:
	Most of the times we are looking for loose coupling for connectivity so that we can switch databases easily, 
	connection pooling for transaction management and distributed systems support. JDBC DataSource is the preferred approach 
	if you are looking for any of these features in your application. 
	
	
Spring DataSource implementation: DriverManagerDataSource!
	<bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource">

		<property name="driverClassName" value="com.mysql.jdbc.Driver" />
		<property name="url" value="jdbc:mysql://localhost:3306/TestDB" />
		<property name="username" value="pankaj" />
		<property name="password" value="pankaj123" />
	</bean>
	
	But we still have to write a lot of boilerplate code: opening connection, statements, closing them, reading the resulet set in a for loop.
	
	
Spring JdbcTemplate to the rescue:
	All we need is to provide the arguments as Object array and implement Callback interfaces such as 
	PreparedStatementSetter and RowMapper for mapping arguments or converting ResultSet data to bean objects.
	
	
JPA: EntityManager
Hibernate: Session


@Lob @Basic(fetch = FetchType.LAZY)
@Column(name="content", nullable=false)
private byte[] content;
 
We have chosen a byte[] to store the content of file. @LobSpecifies that a this persistent property should be persisted as a 
large object to a database-supported large object type which in our case is longblob. 
@Basic annotation is an optional annotation, serving here as placeholder to instruct hibernate to lazy load the binary content.

Java's transient keyword is used to denote that a field is not to be serialized, whereas JPA's @Transient 
annotation is used to indicate that a field is not to be persisted in the database, i.e. their semantics are different.

Hibernate SQLQuery: not recommended because we loose benefits of 1st level cache

1st level cache: - at the Session level
				 - enabled by default
				 - for the current user
2nd level cache: - at the JVM level, Session Factory object --> concurrency is a problem
				 - for all users
				 - disabled by default
					- can enable globally (not recommended)
					- only for certain entities, collections
					- configurable at the Session level with CacheMode
				 - cache all properties (default) or only non-lazy
Query cache: - good for repetitive queries with identical params
			 - if used, best in conjunection with 2LC

session.save() 				- saves changes to db (insert or update)) but does not add entity to persistent context: doesn't track entity
							  and further changes at transaction commit won't get saved. 
							  Works without transaction.

session.saveOrUpdate() 		- adds the entity object to persistent context and track any further changes. 
							  Any further changes are saved at the time of committing transaction, like persist.
							  Works without transaction.

session.persist()			- Hibernate persist is similar to save (with transaction) and it adds the entity object to the persistent context, 
							  so any further changes are tracked. If the object properties are changed before the transaction is committed or 
							  session is flushed, it will also be saved into database.
							  Second difference is that we can use persist() method only within the boundary of a transaction, 
							  so it’s safe and takes care of any cascaded objects.
							  
session.update()			- Hibernate update should be used where we know that we are only updating the entity information. 
							  This operation adds the entity object to persistent context and further changes are tracked and saved when 
							  transaction is committed.
							  
session.merge()				- Hibernate merge can be used to update existing values, however this method create a copy from the passed entity object
							  and return it. The returned object is part of persistent context and tracked for any changes, 
							  passed object is not tracked. This is the major difference with merge() from all other methods. 
							  

							  
SessionFactory (org.hibernate.SessionFactory): 						SessionFactory is an immutable thread-safe cache of compiled mappings for a 
																	single database. We can get instance of org.hibernate.Session using SessionFactory.
																	
Session (org.hibernate.Session): 									Session is a single-threaded, short-lived object representing a conversation 
																	between the application and the persistent store. 
																	It wraps JDBC java.sql.Connection and works as a factory for 
																	org.hibernate.Transaction.
																	
ConnectionProvider (org.hibernate.connection.ConnectionProvider): 	ConnectionProvider is a factory for JDBC connections. It provides abstraction 
																	between the application and underlying javax.sql.DataSource or 
																	java.sql.DriverManager. It is not exposed to application, but it can be 
																	extended by the developer.

TransactionFactory (org.hibernate.TransactionFactory): 				A factory for org.hibernate.Transaction instances.

In its default configuration, the Spring Framework’s transaction infrastructure code only marks a transaction for rollback in the case of runtime,
unchecked exceptions; that is, when the thrown exception is an instance or subclass of RuntimeException. 
(Errors will also - by default - result in a rollback). 
Checked exceptions that are thrown from a transactional method do not result in rollback in the default configuration.

@Transactional: must be applied on public methods to get weaved. Also, only works when invoking the object outside of it - means that invoking 
				another public method from the invoked public method that has @Transactional would take no effect either.
				Rolled back automatically only if unchecked RuntimeException is thrown (checked exceptions does not make the transaction rollback)

Normally both JPA and Hibernate require an xml config (persistence.xml, hibernate.cfg.xml), but with Spring these can be omitted.
(Spring scans the package and packages down for @Entity classes.) @EnableJpaRepositories("com.acme.repositories")

@Entity --> @Respository (Dao) --> @Service --> @Controller/@Restcontroller


********************************
Spring MVC:
********************************

It looks like the 1st folder inside the src/main/resources gets served automatically. 
However with @RequestMapping and viewtechnology (like thymeleaf) used together it is possible to manipulate which html gets sent for which request.
For example: localhost:8080/index.html and localhost:8080 can return the same content!

The WebMvcConfigurerAdapter is for configuring Spring MVC, the replacement of the xml file loaded by the 
	DispatcherServlet for configuring Spring MVC. The WebMvcConfigurerAdapter should be used for a @Configuration class.
	@EnableWebMvc //<mvc:annotation-driven />
	@Configuration
	@ComponentScan({ "com.mkyong.helloworld.web" })
	public class SpringWebConfig extends WebMvcConfigurerAdapter

ServletInitializer: necessary in order for Spring to generate web.xml (project is dynamic webproject and packaging is war - app is deployed to an existing servlet container)
					Without this the war is either not generated or doesn’t work at all (not sure what Gabor said)
					however probably this can be omitted by using "AbstractAnnotationConfigDispatcherServletInitializer" as demonstrated above

AbstractAnnotationConfigDispatcherServletInitializer (ServletInitializer) is the replacement of web.xml. Initializes the servlet container.
public class MyWebInitializer extends AbstractAnnotationConfigDispatcherServletInitializer {

	@Override
	protected Class<?>[] getRootConfigClasses() {
		return new Class[] { SpringRootConfig.class };
	}

	@Override
	protected Class<?>[] getServletConfigClasses() {
		return new Class[] { SpringWebConfig.class };
	}

	@Override
	protected String[] getServletMappings() {
		return new String[] { "/" };
	}
}


WebDataBinder binds custom validators.
To do this, we create a method in controller and annotate it with @InitBinder which plays the role to identify WebDataBinder method in our controller.


Controller:

// this is used to add stuff to spring's model and it ultimately goes into the HttpServletRequest object after the handler executes
@ModelAttribute("myRequestObject")
public MyCommandBean addStuffToRequestScope() {
	System.out.println("Inside of addStuffToRequestScope");
	MyCommandBean bean = new MyCommandBean("Hello World",42);
	return bean;
}
	
	@ModelAttribute refers to a property of the Model object (the M in MVC ;) so let's say we have a form with a form backing object that is called "Person" 
	Then you can have Spring MVC supply this object to a Controller method by using the @ModelAttribute annotation:

	public String processForm(@ModelAttribute("person") Person person){
		person.getStuff();
	}
	Check here for an example (Spring 2.5), also see "Using @ModelAttribute on a method argument" (Spring 3.1).

	On the other hand the annotation is used to define objects which should be part of a Model. So if you want to have a Person object referenced in the Model you can use the following method:
	@ModelAttribute("person")
	public Person getPerson(){
		return new Person();
	}

@Valid asks spring to validate the associated object(Employee). 
BindingResult contains the outcome of this validation and any error that might have occurred during this validation. 
Notice that BindingResult must come right after the validated object else spring won’t be able to validate and an exception been thrown.
Custom errors can be added to the BindingResult: bindingResult.addError(new FieldError(...));					
					
					
********************************
Spring Security
********************************

When security is only the classpath, all endpoints by default requires basic authentitcation (including the static resource files).
CSRF protection is enabled by default.

.formLogin() - injects a Filter to the FilterChain pipeline
			 - invoked only when url is "loginProcessingUrl()"
			 - default authenticationProvider is used which uses basic authentication - can be replaced with inMemory, jdbc, or custom

@Autowired
public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {
	// in memory
	auth.inMemoryAuthentication().withUser("user").password("user");

	// jdbc
	auth.jdbcAuthentication().dataSource(dataSource)
			.usersByUsernameQuery("select username,password, enabled from users where username=?")
			.authoritiesByUsernameQuery("select username, role from user_roles where username=?");

	// custom
	auth.authenticationProvider(authenticationProvider);
}

public class CustomAuthenticationProvider implements AuthenticationProvider { ... }

HttpServletRequest.login(String,String) - to programatically log the user in
HttpServletRequest.logout() - for logout

Annotation based security: @EnableGlobalMethodSecurity

f you’ve used Spring Security before, you’ll know that the framework maintains a chain of filters in order to apply its services. 
You may want to add your own filters to the stack at particular locations or use a Spring Security filter for 
which there isn’t currently a namespace configuration option.


UsernamePasswordAuthenticationFilter: this reads the "username" and "password" from the request and uses the AuthenticationManager
	to authenticate the request.
	
SecurityContextPersistenceFilter: stores the SecurityContext (user info) into the HttpSession
	
UserDetailsService: can be optionally overridden and provide a custom userDetails implementation (reach the db for instance)
GrantedAuthority: UserDetailsService provides them, usually they are roles

	
What we need for authentication:
	- Csrf filter
	- UsernamePasswordAuthenticationFilter - or a custom filter that reads the credentials and invokes AuthenticationManager.authenticate
	- custom AuthenticationProvider
	
SecurityContextRepository: its job is to store the SecurityContext. The default ones stores it in the HttpSession as an attribute.

We can use a custom filter chain by @Bean FilterChainProxy getFilterChain() {...}
	There are 3 mandatory security filters that must be included: SecurityContextPersistenceFilter, ExceptionTranslationFilter, FilterSecurityInterceptor
	
To use a custom FilterChainProxy:
	@Bean(name = "springSecurityFilterChain")
	public FilterChainProxy getFilterChainProxy() {
		SecurityFilterChain chain = new SecurityFilterChain() {

			@Override
			public boolean matches(HttpServletRequest request) {
				// All goes through here
				return true;
			}

			@Override
			public List<Filter> getFilters() {
				List<Filter> filters = new ArrayList<Filter>();

				filters.add(getCookieAuthenticationFilter());
				filters.add(getLogoutFilter());
				filters.add(getUserNamePasswordAuthenticationFilter());
				filters.add(getSecurityContextHolderAwareRequestFilter());
				filters.add(getAnonymousAuthenticationFilter());
				filters.add(getExceptionTranslationFilter());
				filters.add(getFilterSecurityInterceptor());

				return filters;
			}
		};
    
		return new FilterChainProxy(chain);
	}
	
Spring Security’s web infrastructure is based entirely on standard servlet filters. 
It doesn’t use servlets or any other servlet-based frameworks (such as Spring MVC) internally, so it has no strong links 
to any particular web technology.
Spring Security maintains a filter chain internally where each of the filters has a particular responsibility 
and filters are added or removed from the configuration depending on which services are required.


********************************
Spring Session
********************************

Overrdies the default session provided by the servlet container. We can use Gemfire, Redis, Jdbc, MongoDB transparently to store the session.

We have already mentioned that Spring Session provides transparent integration with HttpSession, but what benefits do we get out of this?
	Clustered Sessions - Spring Session makes it trivial to support clustered sessions without being tied to an application container 
					     specific solution.
						 
	Multiple Browser Sessions - Spring Session supports managing multiple users' sessions in a single browser instance 
								(i.e. multiple authenticated accounts similar to Google).

	RESTful APIs - Spring Session allows providing session ids in headers to work with RESTful APIs
	

Redis can be used by:
@Configuration
@EnableRedisHttpSession(maxInactiveIntervalInSeconds=7200)
public class HttpSessionConfig {
	@Bean
    public JedisConnectionFactory connectionFactory() {
		return new JedisConnectionFactory(); 
    }
}


JSESSIONID: this is the cookie that hold the id of the user's session


********************************
Spring Cloud, Microservices
********************************

Eureka, ZooKeeper: service registry and provide network discovery (prefer to use eureka since it is more resilient to failures)
Hystrix: fallback methods in case of failures - on the edge service, microservices
Microservice: invoked by the edge service, and they can invoke each other (hystrix needed if invoking other services for the best user experience - avoid showing stacktraces)
Zuul: egde service implementation: micro proxy, api gateway
Actuator: monitoring capabilities via jmx and rest api (use with the config server)
Config server: central store for configurations of the participants of the system
Hystrix dashboard, Turbine: use for health monitoring
Ribbon: round robin load balancer


Config service: just a super lightweight service that is used to centralize the configuration data 
	Scenario is that I have multiple microservices and do not want to store config one by one for each service, rather I would store them in a 
	central config server.
	
	@EanbleConfigServer
	application.properties: spring.cloud.config.server.git.uri=${HOME}/Desktop/config <-- in this folder resides the configs for the various microservices	
							server.port=8888

Service registry: (Eureka for example)
				  It is like a phonebook for the cloud.
				  Just a registry the regisers microservices and enables client side loadbalancing.
	
	<dependency>
		<groupId>org.springframework.cloud</groupId>
		<artifactId>spring-could-starter-config</artifactId>
	</dependency>
	
	@EnableEurekaServer
	
	bootstrap.properties: spring.application.name=eureka-service
						  spring.cloud.config.uri=http://localhost:8888	<-- config is from the config server
						  
	Start the service and visit it in the browser: you'll see a nice console window.
						  
MicroService:

	1. config comes from the config server
	<dependency>
		<groupId>org.springframework.cloud</groupId>
		<artifactId>spring-could-starter-config</artifactId>
	</dependency>

	bootstrap.properties: string.application.name=reservation-service
						  spring.cloud.config.uri=http://localhost:8888

	2. teach this service to talk to Eureka
	<dependency>
		<groupId>org.springframework.cloud</groupId>
		<artifactId>spring-could-starter-eureka</artifactId>
	</dependency>

	@EnableDiscoveryClient - now service will get registered in Eureka
						   - going to Eureka's console will display the this service ("reservation-service", comes from the bootstrap.properties)
						   
						   
Edge service: there are two types:
				1. Micro proxy: bindlys forward packages outside to the datacenter inside the loadbalancer
				2. API gateway: transforms the request to the services behind the loadbalancer
				
	<dependency>
		<groupId>org.springframework.cloud</groupId>
		<artifactId>spring-could-starter-config</artifactId>
	</dependency>
				
	1. Micro proxy: Eureka discovery, Config client, Hystrix (for circuit breakers), Zuul (for micro proxy), Stream Redis, Zipkin (distributed tracing)
	
		@EnableDiscoveryClient
		@EnableZuulProxy - blindly forward the requests from the edge service into the service that we reference in the request's url
			localhost:9999/reservation-service/reservations: {edge-service}/{serviceId as registered in the service registry}/{url in the referenced service}
		
		bootstrap.properties: sptring.application.name=reservation-client
								spring.cloud.config.uri=http://localhost:8888	<-- config is from the config server
								
	2. Api gateway: at this point same the Micro proxy: to test, localhost:9999/reservations/name
		
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-hateoas</artifactId>
		</dependency>
		
		Hystrix: allows us to specify a fallback path if the microserve request goes wrong
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-boot-starter-hystrix</artifactId>
		</dependency>
		@EnableCircuitBreaker
		
		@RestController
		@RequestMapping("/reservations")
		public class ReservationApiGatewayController {

			@Autowired
			private RestTemplate restTemplate;

			public Collection<String> getReservationNamesFallback() {
				return new ArrayList<>();
			}

			@HystrixCommand(fallbackMethod = "getReservationNamesFallback")
			@RequestMapping(method = RequestMethod.GET, value = "/names")
			public Collection<String> getReservationNames() {

				ParameterizedTypeReference<Resources<Reservation>> ptr = new ParameterizedTypeReference<Resources<Reservation>>() {};

				// "reservation-service" indentifies the microservice we are to call
				// this works if there is 1 service instance or there are multiple instances
				// however it blows chunks of there is no service, that is why the fallbackMethod specified
				ResponseEntity<Resources<Reservation>> entity = this.restTemplate.exchange("http://reservation-service/reservations", ptr);
		
				return entity
					.getBody()
					.getContent()
					.stream()
					.map(Reservation::getReservationName)
					.collapseInCollections(Collectors.toList()));
			}
		}
		
		When the url gets executed it 
			1. grabs the serviceId (reservation-service)
			2. goes to the service registry
			3. gets all registered instances of reservation-service services from the registry
			4. invokes one instance via Ribbon (which is a round-robin load-balander, each instance has the same chance to get invoked)
	
	
	This is good for reading, however for writing which requires synchronization is not good.
	We could use distributed transations but Josh Long urges us not to, it just slows down aggregate system.
	Instead use messaging: forward to the service on a message bus: job is put into a queue (buffer) and eventually gets picked up by the service.
	
	
	Spring cloud stream: a way of describing messaging based services and compose them outside of the actual code.
	
	2.1. continuing the Api gateway: the sender, producer - reservation-client
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-could-starter-stream-redis</artifactId>
		</dependency>
		Redis is just one implmenation, we could use "Rabbit and queue" or whatever
		
		@EanbleBinding(Source.class) - this enables spring cloud stream, this is the producer
		
		@RestController
		@RequestMapping("/reservations")
		public class ReservationApiGatewayController {
		
			@Autowired
			private Source source;

			@RequestMapping(method = RequestMethod.POST)
			public void writeReservation(@RequestBody Reservation r) {
				Message<String> msg = MessageBuilder<T>.withPayload(r.getReservationName())build();
				this.source.output().send(msg;)
			}
			
			...
		}
		
		where the request is sent is in the configuration: reservation-client: spring.cloud.stream.bindings.ouput: "reservations"
														   reservation-service: spring.cloud.stream.bindings.input: "reservations"
														   
														   
	2.2 the consumer, reservation-service
	
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-could-starter-stream-redis</artifactId>
		</dependency>
		
		@EanbleBinding(Sink.class)
		@IntegrationComponentScan - using Spring Integration
		
		@MessageEndpoint
		class ReservationProcessor {
		
			@ServiceActivator(inputChannel = Sink.INPUT)
			public void acceptNewReservations(String rn) {
				this.reservationRepository.save(new Reservation(rn));
			}
		}
		

Hystrix dashboard, H2 console - good stuff, start.spring.io starters
Spring cloud handles Single Sign on, Oath2 is dead simple



********************************
Spring cloud deployment
********************************

Cloud Foundry: PaaS platform
BOSH: how you automate, install and congfigure a CF system (among other things, it does a lot of stuff)



********************************
Spring IO
********************************

Spring IO Platform brings together the core Spring APIs into a cohesive platform for modern applications. 
It provides versions of numerous projects in the Spring portfolio along with their dependencies that are tested and known to work together.

Overriding a version using maven
	<properties>
		<foo.version>1.1.0.RELEASE</foo.version>
	</properties>
	
	
	
********************************
Spring Data
********************************

The goal of Spring Data repository abstraction is to significantly reduce the amount of boilerplate code required to implement data 
access layers for various persistence stores.

Auditing: 
	We provide @CreatedBy, @LastModifiedBy to capture the user who created or modified the entity as well as 
	@CreatedDate and @LastModifiedDate to capture the point in time this happened.
	
	@Entity
	@EntityListeners(AuditingEntityListener.class)
	public class MyEntity { }
	
	interface UserRepository extends Repository<User, Long> {
		// Redeclaration of a CRUD method
		@Lock(LockModeType.READ);
		List<User> findAll();
	}
	

	
Autogenerate sqls: CrudRepository, PagingAndSortingRepository

Async query results: @Async
					 CompletableFuture<User> findOneByFirstname(String firstname)
					 
Adding custom behavior to all repositories
	@NoRepositoryBean
	public interface MyRepository<T, ID extends Serializable>
		extends PagingAndSortingRepository<T, ID> {

		void sharedCustomMethod(ID id);
	}
	
	public class MyRepositoryImpl<T, ID extends Serializable> extends SimpleJpaRepository<T, ID> implements MyRepository<T, ID> {

		private final EntityManager entityManager;

		public MyRepositoryImpl(JpaEntityInformation entityInformation, EntityManager entityManager) {
			super(entityInformation, entityManager);

			// Keep the EntityManager around to used from the newly introduced methods.
			this.entityManager = entityManager;
		}

		public void sharedCustomMethod(ID id) {
			// implementation goes here
		}
	}
	
	
The results of query methods can be processed incrementally by using a Java 8 Stream<T> as return type. 
Instead of simply wrapping the query results in a Stream data store specific methods are used to perform the streaming.	
	@Query("select u from User u")
	Stream<User> findAllByCustomQueryAndStream();
	
	Stream<User> readAllByFirstnameNotNull();
	
	
@Query("select u from User u where u.firstname = :firstname or u.lastname = :lastname")
User findByLastnameOrFirstname(@Param("lastname") String lastname, @Param("firstname") String firstname);
								 
@Query(value = "SELECT * FROM USERS WHERE LASTNAME = ?1",
	   countQuery = "SELECT count(*) FROM USERS WHERE LASTNAME = ?1",
       nativeQuery = true)
Page<User> findByLastname(String lastname, Pageable pageable);


	
********************************
Spring Data Rest - good for integration: consumer can easily discover our API - HATEOAS
********************************

HATEOAS (Hypermedia as the Engine of Application State) is a constraint of the REST application architecture.

A hypermedia-driven site provides information to navigate the site's REST interfaces dynamically by 
including hypermedia links with the responses. This capability differs from that of SOA-based systems and WSDL-driven interfaces. 
With SOA, servers and clients usually must access a fixed specification that might be staged somewhere else on the website, on another website, 
or perhaps distributed by email.

A core principle of HATEOAS is that resources should be discoverable through the publication of links that point to the available resources. 
There are a few competing de-facto standards of how to represent links in JSON. By default, 
Spring Data REST uses HAL to render responses. HAL defines links to be contained in a property of the returned document.


Spring Data REST officially supports: Spring Data Jpa, Spring Data MongoDB, GemFire, Cassandra, Neo4j

public interface OrderRepository extends CrudRepository<Order, Long> { }. For this repository, Spring Data REST exposes a collection resource at /orders.

curl -v http://localhost:8080/

	< HTTP/1.1 200 OK
	< Content-Type: application/hal+json

	{ "_links" : {
		"orders" : {
		"href" : "http://localhost:8080/orders"
		},
		"profile" : {
		"href" : "http://localhost:8080/api/alps"
		}
	  }
	}


	
********************************
Spring Batch
********************************

Spring Batch is not a scheduling framework.
Usage:
	A typical batch program generally reads a large number of records from a database, file, or queue, processes the data in some fashion, 
	and then writes back data in a modified form. Spring Batch automates this basic batch iteration, providing the capability to process similar 
	transactions as a set, typically in an offline environment without any user interaction. 
	
Business Scenarios:
	Commit batch process periodically
	Concurrent batch processing: parallel processing of a job
	Staged, enterprise message-driven processing
	Massively parallel batch processing
	Manual or scheduled restart after failure
	Sequential processing of dependent steps (with extensions to workflow-driven batches)
	Partial processing: skip records (e.g. on rollback)
	Whole-batch transaction: for cases with a small batch size or existing stored procedures/scripts
	
Processing options:
	1. Normal processing in a batch window during off-line
	2. Concurrent batch / on-line processing
	3. Parallel processing of many different batch runs or jobs at the same time
	4. Partitioning (i.e. processing of many instances of the same job at the same time)
	
	1. For simple batch processes running in a separate batch window, where the data being updated is not required by on-line users or other batch processes, 
		concurrency is not an issue and a single commit can be done at the end of the batch run.
		
	2. Batch applications processing data that can simultaneously be updated by on-line users, should not lock any data (either in the database or in files) which 
		could be required by on-line users for more than a few seconds. Also updates should be committed to the database at the end of every few transaction. 
		This minimizes the portion of data that is unavailable to other processes and the elapsed time the data is unavailable.
		
	3. Parallel processing allows multiple batch runs / jobs to run in parallel to minimize the total elapsed batch processing time. This is not a problem as long 
		as the jobs are not sharing the same files, db-tables or index spaces. If they do, this service should be implemented using partitioned data. 
	
	4. Using partitioning allows multiple versions of large batch applications to run concurrently. The purpose of this is to reduce the elapsed time required to 
		process long batch jobs. Processes which can be successfully partitioned are those where the input file can be split and/or the main database tables partitioned 
		to allow the application to run against different sets of data.

		
Job: A Job is an entity that encapsulates an entire batch process. It contains one or more steps.
JobIstance: JobInstance = Job + identifying JobParameters. A JobInstance refers to the concept of a logical job run.
JobExecution: A JobExecution refers to the technical concept of a single attempt to run a Job.
Setp: ItemReader + ItemProcessor + ItemWriter
StepExecution: represents a single attempt to execute a Step
JobRepository: JobRepository is the persistence mechanism for all of the Stereotypes mentioned above.
JobLauncher represents a simple interface for launching a Job with a given set of JobParameters.
ItemReader is an abstraction that represents the retrieval of input for a Step, one item at a time. When the ItemReader has exhausted the items it can provide, it will indicate this by returning null.
ItemWriter is an abstraction that represents the output of a Step, one batch or chunk of items at a time.
ItemProcessor is an abstraction that represents the business processing of an item. While the ItemReader reads one item, and the ItemWriter writes them, the ItemProcessor 
	provides access to transform or apply other business processing. If, while processing the item, it is determined that the item is not valid, returning null indicates that the item should not be written out.
	
One key issue when executing a batch job concerns the behavior of a Job when it is restarted. The launching of a Job is considered to be a 'restart' if a JobExecution already exists for the particular JobInstance.

In-Memory Repository: There are scenarios in which you may not want to persist your domain objects to the database.
	<bean id="jobRepository" class="org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean">
		<property name="transactionManager" ref="transactionManager"/>
	</bean>
	
Chunk-Oriented Processing
	Spring Batch uses a 'Chunk Oriented' processing style within its most common implementation. Chunk oriented processing refers to reading the data one at a time,
	and creating 'chunks' that will be written out, within a transaction boundary. One item is read in from an ItemReader, handed to an ItemProcessor, and aggregated. 
	Once the number of items read equals the commit interval, the entire chunk is written out via the ItemWriter, and then the transaction is committed.
	
All batch processing can be described in its most simple form as reading in large amounts of data, performing some type of calculation or transformation, and writing the result out.
	Spring Batch provides three key interfaces to help perform bulk reading and writing: ItemReader, ItemProcessor and ItemWriter.
	

Scaling and Parallel Processing
	Multi-threaded Step: The result of the above configuration will be that the Step executes by reading, processing and writing each chunk of items (each commit interval)
					 in a separate thread of execution. Note that this means there is no fixed order for the items to be processed, and a chunk might contain items that are 
					 non-consecutive compared to the single-threaded case. In addition to any limits placed by the task executor (e.g. if it is backed by a thread pool), 
					 there is a throttle limit in the tasklet configuration which defaults to 4. You may need to increase this to ensure that a thread pool is fully utilised.
					 
	Parallel Steps: steps execute parallel

	Remote Chunking: In Remote Chunking the Step processing is split across multiple processes, communicating with each other through some middleware.

	Paritioning: Spring Batch also provides an SPI for partitioning a Step execution and executing it remotely.



********************************
Spring 	Integration	
********************************

In addition to wiring together fine-grained components, Spring Integration provides a wide selection of channel adapters and gateways to 
communicate with external systems. Channel Adapters are used for one-way integration (send or receive); 
gateways are used for request/reply scenarios (inbound or outbound).


Spring Integration provides an extension of the Spring programming model to support the well-known Enterprise Integration Patterns. 
It enables lightweight messaging within Spring-based applications and supports integration with external systems via declarative adapters. 
Those adapters provide a higher-level of abstraction over Spring’s support for remoting, messaging, and scheduling.

Spring Integration is motivated by the following goals:
	Provide a simple model for implementing complex enterprise integration solutions.
	Facilitate asynchronous, message-driven behavior within a Spring-based application.
	Promote intuitive, incremental adoption for existing Spring users.
Spring Integration is guided by the following principles:
	Components should be loosely coupled for modularity and testability.
	The framework should enforce separation of concerns between business logic and integration logic.
	Extension points should be abstract in nature but within well-defined boundaries to promote reuse and portability.
	
Message: In Spring Integration, a Message is a generic wrapper for any Java object combined with metadata used by the framework while handling 
		 that object. It consists of a payload and headers.
Message Channel: A Message Channel represents the "pipe" of a pipes-and-filters architecture. 
				 Producers send Messages to a channel, and consumers receive Messages from a channel. 
				 The Message Channel therefore decouples the messaging components, and also provides a convenient point for interception 
				 and monitoring of Messages.
				 
				 A Message Channel may follow either Point-to-Point or Publish/Subscribe semantics. With a Point-to-Point channel, 
				 at most one consumer can receive each Message sent to the channel. Publish/Subscribe channels, on the other hand, 
				 will attempt to broadcast each Message to all of its subscribers. Spring Integration supports both of these.
				 will attempt to broadcast each Message to all of its subscribers. Spring Integration supports both of these.
Message Endpoint: One of the primary goals of Spring Integration is to simplify the development of enterprise integration solutions 
				  through inversion of control. This means that you should not have to implement consumers and producers directly,
				  and you should not even have to build Messages and invoke send or receive operations on a Message Channel. 
				  Instead, you should be able to focus on your specific domain model with an implementation based on plain Objects. 
				  Then, by providing declarative configuration, you can "connect" your domain-specific code to the messaging infrastructure
				  provided by Spring Integration. The components responsible for these connections are Message Endpoints.
				  
Message Endpoints: A Message Endpoint represents the "filter" of a pipes-and-filters architecture. As mentioned above, the endpoint’s 
				   primary role is to connect application code to the messaging framework and to do so in a non-invasive manner. 
				   In other words, the application code should ideally have no awareness of the Message objects or the Message Channels.
				   This is similar to the role of a Controller in the MVC paradigm. Just as a Controller handles HTTP requests, 
				   the Message Endpoint handles Messages. Just as Controllers are mapped to URL patterns, Message Endpoints are mapped 
				   to Message Channels.
Transformer: A Message Transformer is responsible for converting a Message’s content or structure and returning the modified Message.
Filter: A Message Filter determines whether a Message should be passed to an output channel at all. 
Router: A Message Router is responsible for deciding what channel or channels should receive the Message next (if any). 
Service Activator: A Service Activator is a generic endpoint for connecting a service instance to the messaging system.
Channel Adapter: A Channel Adapter is an endpoint that connects a Message Channel to some other system (external system) or transport. 
				 Channel Adapters may be either inbound or outbound. Typically, the Channel Adapter will do some mapping between the 
				 Message and whatever object or resource is received-from or sent-to the other system (File, HTTP Request, JMS Message, etc).
				 Depending on the transport, the Channel Adapter may also populate or extract Message header values. 
				 Spring Integration provides a number of Channel Adapters, and they will be described in upcoming chapters.

@EnableIntegration
@IntegrationComponentScan
@EnablePublisher

MessagingTemplate: send, receive, sendAndReceive

Channel Adapter: A Channel Adapter is a Message Endpoint that enables connecting a single sender or receiver to a Message Channel. 
				 Spring Integration provides a number of adapters out of the box to support various transports, such as JMS, File, HTTP,
				 Web Services, Mail, and more. 
Messaging Bridge: A Messaging Bridge is a relatively trivial endpoint that simply connects two Message Channels or Channel Adapters.
MessageBuilder 
	
	
********************************
Spring Framework
********************************

The syntax ${x:${y}} is Spring property shorthand for ${x} != null ? ${x} : ${y}.
eureka:
  instance:
    metadataMap:
      instanceId: ${spring.application.name}:${spring.application.instance_id:${server.port}}

Dependency Injection:
	@PostConstruct
	@PreDestroy
	

Components: 
	Core Container: consists of the spring-core, spring-beans, spring-context, spring-context-support, and spring-expression 
					(Spring Expression Language) modules. he Context module also supports Java EE features such as EJB, JMX, and basic remoting.
	AOP and Instrumentation: aspect-oriented programming implementation allowing you to define, for example, method interceptors and pointcuts to cleanly decouple code that implements functionality that should be separated.
	Messaging: Spring Framework 4 includes a spring-messaging module with key abstractions from the Spring Integration project such as Message, MessageChannel, MessageHandler, and others to serve as a foundation for messaging-based applications.
	Data Access/Integration: The Data Access/Integration layer consists of the JDBC, ORM, OXM, JMS, and Transaction modules.
	Web: The Web layer consists of the spring-web, spring-webmvc, spring-websocket, and spring-webmvc-portlet modules.
		The spring-web module provides basic web-oriented integration features such as multipart file upload functionality and the 
			initialization of the IoC container using Servlet listeners and a web-oriented application context. 
			It also contains an HTTP client and the web-related parts of Spring’s remoting support.
		The spring-webmvc module (also known as the Web-Servlet module) contains Spring’s model-view-controller (MVC) and REST Web Services
			implementation for web applications. Spring’s MVC framework provides a clean separation between domain model code and 
			web forms and integrates with all of the other features of the Spring Framework.
	Test: The spring-test module supports the unit testing and integration testing of Spring components with JUnit or TestNG. It provides consistent 
		loading of Spring ApplicationContexts and caching of those contexts. It also provides mock objects that you can use to test your code in isolation.
	
	
For logging JCL (Jakarta Common Logging) library is used, but it was a mistake. It can be excluded from the dependencies of spring-core and use
SLF4J  instead.
		
JMS improvements: Synchronous request-reply operations support in JmsTemplate
Caching improvements

Beans by default are Singletons and eagerly initialized. Use @Lazy for lazy initialization.
Bean scopes: singleton, prototype, request, session, globalsession, application, websocket

Method injection: used typically when a Singleton bean (A) has prototype dependency (B) and A needs new B instances.
	- inject the ApplicationContext and use the Service Locator pattern is the only solution
	
To interact with the container’s management of the bean lifecycle, you can implement the Spring InitializingBean and DisposableBean interfaces.
	BUT: The JSR-250 @PostConstruct and @PreDestroy annotations are generally considered best practice for receiving lifecycle callbacks in a modern 
	Spring application. Using these annotations means that your beans are not coupled to Spring specific interfaces.
	
	
7.6.3 Other Aware interfaces: ApplicationContextAware, BeanNameAware, ServletConfigAware, ServletContextAware
7.9 Annotation-based container configuration

@Required, 
@Autowired - resolves dependencies by type
@Primary - indicates that a particular bean should be given preference when multiple beans are candidates to be autowired to a single-valued dependency
@Qualifier - specify the name of the dependency (use @Beans(name = "..."))
@Bean - can be used on methods, by default the beans's name is the name of the method
@Resource - takes a name attribute, and by default Spring interprets that value as the bean name to be injected. 
			In other words, it follows by-name semantics, like this:
				@Resource(name="myMovieFinder")
				public void setMovieFinder(MovieFinder movieFinder) {
					this.movieFinder = movieFinder;
				}
@Component and further stereotype annotations: @Service, @Repository, @Controller
@Component: is a generic stereotype for any Spring-managed component.
@Repository annotation is a marker for any class that fulfills the role or stereotype of a repository (also known as Data Access Object or DAO). 
	Among the uses of this marker is the automatic translation of exceptions as described in Section 20.2.2, “Exception translation”.
	(unchecked exceptions for @Transactional to rollback the commit)

	
7.10.3 Automatically detecting classes and registering bean definitions
	To autodetect these classes and register the corresponding beans, you need to add @ComponentScan to your @Configuration class, 
	where the basePackages attribute is a common parent package for the two classes. 
	If basePackages is not specified on the @ComponentScan, then the package of the class it is applied on gets used.
	
7.10.4 Using filters to customize scanning

7.10.5 Defining metadata
	@Bean, @Lazy, @Qualifier, @Scope can be used together

	@Service("myMovieLister")
	public class SimpleMovieLister - bean's name is "myMovieLister"

	@Repository
	public class MovieFinderImpl - bean's name is "movieFinderImpl"


7.11 Using JSR 330 Standard Annotations
	@Inject vs @Autowired
	@Named vs @Component - the two are identical
	
	
7.11.3 Limitations of JSR-330 standard annotations

7.12 Java-based container configuration
	The central artifacts in Spring’s new Java-configuration support are @Configuration-annotated classes and @Bean-annotated methods.
	
	@Bean - method-level annotation and is used to indicate that a method instantiates, configures and initializes a new object 
			to be managed by the Spring IoC container.
	@Bean(initMethod = "init")
	@Bean(destroyMethod = "cleanup")
	@Configuration - indicates that its primary purpose is as a source of bean definitions. 
					 Furthermore, @Configuration classes allow inter-bean dependencies to be defined by simply calling other 
					 @Bean methods in the same class. 
					 
		
	Full @Configuration vs 'lite' @Beans mode?
	When @Bean methods are declared within classes that are not annotated with @Configuration they are referred to as being processed in a 'lite' mode.
	For example, bean methods declared in a @Component or even in a plain old class will be considered 'lite'.
	Unlike full @Configuration, lite @Bean methods cannot easily declare inter-bean dependencies. 
	Usually one @Bean method should not invoke another @Bean method when operating in 'lite' mode.
	Only using @Bean methods within @Configuration classes is a recommended approach of ensuring that 'full' mode is always used. 
	This will prevent the same @Bean method from accidentally being invoked multiple times and helps to reduce subtle bugs that can be hard 
	to track down when operating in 'lite' mode.

	@Import - annotation allows for loading @Bean definitions from another configuration class
	
Conditionally include @Configuration classes or @Bean methods
	It is often useful to conditionally enable or disable a complete @Configuration class, or even individual @Bean methods, 
	based on some arbitrary system state.
	
	@Profile - activate beans only when a specific profile has been enabled in the Spring Environment
		spring.profiles=dev,prod
		spring.profiles.active=dev
	@Conditional
	
	
Configuration injection

	@ConfigurationProperties(prefix = "spring.dsMsSQL")
	public class MsSQLDataSourceConfiguration extends DatabaseConfig {
		// DatabaseConfig's fields are propagated with config properties from application.properties that match the prefix
		// like spring.dsMsSQL.password <--- "password" field gets filled with the value of this
	}

	@Configuration
	@PropertySource("classpath:neo4j.properties")
	public class Neo4jConfig {
		@Autowired
		Environment environment;
	}
	
	@PropertySource - provides a convenient and declarative mechanism for adding a PropertySource to Spring’s Environment
	
	
7.15.1 Internationalization using MessageSource

	MessageSource, HierarchicalMessageSource interfaces
	
	
8.2 The Resource interface

	Spring’s Resource interface is meant to be a more capable interface for abstracting access to low-level resources.
	
	UrlResource: The UrlResource wraps a java.net.URL, and may be used to access any object that is normally accessible via a URL, 
				 such as files, an HTTP target, an FTP target, etc.
	ClassPathResource
	FileSystemResource: his is a Resource implementation for java.io.File handles. It obviously supports resolution as a File, and as a URL.
	ServletContextResource
	InputStreamResource
	ByteArrayResource
	
	ResourceLoader: The ResourceLoader interface is meant to be implemented by objects that can return (i.e. load) Resource instances.
		Resource template = ctx.getResource("classpath:some/resource/path/myTemplate.txt");
		Resource template = ctx.getResource("file:///some/resource/path/myTemplate.txt");
		Resource template = ctx.getResource("http://myhost.com/resource/path/myTemplate.txt");
		
		
9. Validation, Data Binding, and Type Conversion
		
	Spring Framework 4.0 supports Bean Validation 1.0 (JSR-303) and Bean Validation 1.1 (JSR-349) in terms of setup support, 
	also adapting it to Spring’s Validator interface.
	
9.5.1 Converter SPI
	org.springframework.core.convert.converter.Converter interface
	
11. Aspect Oriented Programming with Spring
	Aspect: a modularization of a concern that cuts across multiple classes. Transaction management is a good example of a crosscutting 
			concern in enterprise Java applications. In Spring AOP, aspects are implemented using regular classes 
			(the schema-based approach) or regular classes annotated with the @Aspect annotation (the @AspectJ style).
	Join point: a point during the execution of a program, such as the execution of a method or the handling of an exception. 
			In Spring AOP, a join point always represents a method execution.
	Advice: action taken by an aspect at a particular join point. Different types of advice include "around," "before" and "after" advice.
			(Advice types are discussed below.) Many AOP frameworks, including Spring, model an advice as an interceptor, maintaining a chain 
			of interceptors around the join point.
	Pointcut: a predicate that matches join points. Advice is associated with a pointcut expression and runs at any join point matched by 
			the pointcut (for example, the execution of a method with a certain name). The concept of join points as matched by pointcut 
			expressions is central to AOP, and Spring uses the AspectJ pointcut expression language by default.
	Introduction: declaring additional methods or fields on behalf of a type. Spring AOP allows you to introduce new interfaces 
			(and a corresponding implementation) to any advised object. For example, you could use an introduction to make a bean implement 
			an IsModified interface, to simplify caching. (An introduction is known as an inter-type declaration in the AspectJ community.)
	Target object: object being advised by one or more aspects. Also referred to as the advised object. Since Spring AOP is implemented 
			using runtime proxies, this object will always be a proxied object.
	AOP proxy: an object created by the AOP framework in order to implement the aspect contracts (advise method executions and so on). 
			In the Spring Framework, an AOP proxy will be a JDK dynamic proxy or a CGLIB proxy.
	Weaving: linking aspects with other application types or objects to create an advised object. This can be done at compile time 
			(using the AspectJ compiler, for example), load time, or at runtime. Spring AOP, like other pure Java AOP frameworks, 
			performs weaving at runtime.
	
	
	Types of advice:
		Before advice: Advice that executes before a join point, but which does not have the ability to prevent execution 
			flow proceeding to the join point (unless it throws an exception).
		After returning advice: Advice to be executed after a join point completes normally: for example, if a method returns without
			throwing an exception.
		After throwing advice: Advice to be executed if a method exits by throwing an exception.
		After (finally) advice: Advice to be executed regardless of the means by which a join point exits (normal or exceptional return).
		Around advice: Advice that surrounds a join point such as a method invocation. This is the most powerful kind of advice. 
			Around advice can perform custom behavior before and after the method invocation. It is also responsible for choosing 
			whether to proceed to the join point or to shortcut the advised method execution by returning its own return value or 
			throwing an exception.
			
	@Configuration
	@EnableAspectJAutoProxy
	public class AppConfig {
	}
	
	@Aspect
	public class NotVeryUsefulAspect {
	
		@Pointcut("execution(public * *(..))")
		private void anyPublicOperation() {}

		@Pointcut("within(com.xyz.someapp.trading..*)")
		private void inTrading() {}

		@Pointcut("anyPublicOperation() && inTrading()")
		private void tradingOperation() {}
		
		@Before("com.xyz.myapp.SystemArchitecture.dataAccessOperation()")
		public void doAccessCheck() {
		}
		
		@AfterReturning("com.xyz.myapp.SystemArchitecture.dataAccessOperation()")
		public void doAccessCheck() {
		}
		
		@AfterReturning(pointcut="com.xyz.myapp.SystemArchitecture.dataAccessOperation()", returning="retVal")
		public void doAccessCheck(Object retVal) {
		}
		
		@AfterThrowing("com.xyz.myapp.SystemArchitecture.dataAccessOperation()")
		public void doRecoveryActions() {
		}
	
		@After("com.xyz.myapp.SystemArchitecture.dataAccessOperation()")
		public void doReleaseLock() {
		}
	
		@Around("com.xyz.myapp.SystemArchitecture.businessService()")
		public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable {
			// start stopwatch
			Object retVal = pjp.proceed();
			// stop stopwatch
			return retVal;
    }
}


Transaction Management

	PlatformTransactionManager: JtaTransactionManager, HibernateTransactionManager
	
17.4.2 Low-level synchronization approach

	DataSourceUtils (for JDBC), EntityManagerFactoryUtils (for JPA), SessionFactoryUtils, PersistenceManagerFactoryUtils (for JDO)
	
	For example, in the case of JDBC, instead of the traditional JDBC approach of calling the getConnection() method on the DataSource, 
	you instead use Spring’s org.springframework.jdbc.datasource.DataSourceUtils class as follows:
		Connection conn = DataSourceUtils.getConnection(dataSource);
		
	@Transactional - declarative transaction support are that this support is enabled via AOP proxies
	
		- Propagation setting is REQUIRED.
		- Isolation level is DEFAULT.
		- Transaction is read/write. - not read-only by default
		- Transaction timeout defaults to the default timeout of the underlying transaction system, or none if timeouts are not supported.
		- Any RuntimeException triggers rollback, and any checked Exception does not.
		
		When using proxies, you should apply the @Transactional annotation only to methods with public visibility. 
		If you do annotate protected, private or package-visible methods with the @Transactional annotation, no error is raised, 
		but the annotated method does not exhibit the configured transactional settings. 
		Consider the use of AspectJ (see below) if you need to annotate non-public methods.
		
		Spring recommends that you only annotate concrete classes (and methods of concrete classes) with the @Transactional annotation, as opposed 
		to annotating interfaces. You certainly can place the @Transactional annotation on an interface (or an interface method), but this works only 
		as you would expect it to if you are using interface-based proxies. The fact that Java annotations are not inherited from interfaces means that
		if you are using class-based proxies ( proxy-target-class="true") or the weaving-based aspect ( mode="aspectj"), then the transaction 
		settings are not recognized by the proxying and weaving infrastructure, and the object will not be wrapped in a transactional proxy, 
		which would be decidedly bad.
		
		In proxy mode (which is the default), only external method calls coming in through the proxy are intercepted. This means that 
		self-invocation, in effect, a method within the target object calling another method of the target object, will not lead to an
		actual transaction at runtime even if the invoked method is marked with @Transactional. Also, the proxy must be fully initialized
		to provide the expected behaviour so you should not rely on this feature in your initialization code, i.e. @PostConstruct.
		
		Consider the use of AspectJ mode (see mode attribute in table below) if you expect self-invocations to be wrapped with transactions
		as well. In this case, there will not be a proxy in the first place; instead, the target class will be weaved (that is, its byte 
		code will be modified) in order to turn @Transactional into runtime behavior on any kind of method.


		If you find you are repeatedly using the same attributes with @Transactional on many different methods, then 
		Spring’s meta-annotation support allows you to define custom shortcut annotations for your specific use cases. 
		For example, defining the following annotations		
			@Target({ElementType.METHOD, ElementType.TYPE})
			@Retention(RetentionPolicy.RUNTIME)
			@Transactional("account")
			public @interface AccountTx {
			}
			
			
17.5.7 Transaction propagation
	PROPAGATION_REQUIRED: However, in the case where an inner transaction scope sets the rollback-only marker, the outer transaction has not decided on 
		the rollback itself, and so the rollback (silently triggered by the inner transaction scope) is unexpected. 
		A corresponding UnexpectedRollbackException is thrown at that point. 
	PROPAGATION_REQUIRES_NEW: uses a completely independent transaction for each affected transaction scope. In that case, the underlying 
		physical transactions are different and hence can commit or roll back independently, with an outer transaction not affected by an 
		inner transaction’s rollback status.
	PROPAGATION_NESTED : uses a single physical transaction with multiple savepoints that it can roll back to. Such partial rollbacks 
		allow an inner transaction scope to trigger a rollback for its scope, with the outer transaction being able to continue the physical 
		transaction despite some operations having been rolled back. This setting is typically mapped onto JDBC savepoints, so will only work 
		with JDBC resource transactions. See Spring’s DataSourceTransactionManager.
			
			
17.6 Programmatic transaction management

	Using the TransactionTemplate.
	Using a PlatformTransactionManager implementation directly.
	
18.3 Annotations used for configuring DAO or Repository classes
	@Repository
	Any DAO or repository implementation will need to access to a persistence resource, depending on the persistence technology used; 
	for example, a JDBC-based repository will need access to a JDBC DataSource; a JPA-based repository will need access to an EntityManager. 
	The easiest way to accomplish this is to have this resource dependency injected using one of the
	@Autowired,, @Inject, @Resource or @PersistenceContext annotations. Here is an example for a JPA repository:
	
	@Repository
	public class JpaMovieFinder implements MovieFinder {
    @PersistenceContext
		private EntityManager entityManager;
	}
	
	
DataSource
	DriverManagerDataSource dataSource = new DriverManagerDataSource();
	dataSource.setDriverClassName("org.hsqldb.jdbcDriver");
	dataSource.setUrl("jdbc:hsqldb:hsql://localhost:");
	dataSource.setUsername("sa");
	dataSource.setPassword("");
	
	Only use the DriverManagerDataSource class should only be used for testing purposes since it does not provide pooling and will perform poorly 
	when multiple requests for a connection are made.
	Always use the DataSource provided by the container via JNDI
	

	DataSourceUtils
		The DataSourceUtils class is a convenient and powerful helper class that provides static methods to obtain connections from JNDI 
		and close connections if necessary. It supports thread-bound connections with, for example, DataSourceTransactionManager.
	
	
	JPA: 3 ways to set up JPA with spring: LocalEntityManagerFactoryBean, EntityManagerFactory from JNDI, LocalContainerEntityManagerFactoryBean
		Use this latter option for full JPA capabilities in a Spring-based application environment. 
	
	
21.2 Marshaller and Unmarshaller
	As stated in the introduction, a marshaller serializes an object to XML, and an unmarshaller deserializes XML stream to an object. 
	In this section, we will describe the two Spring interfaces used for this purpose.
	

22. Web MVC framework

	The Spring Web model-view-controller (MVC) framework is designed around a DispatcherServlet that dispatches requests to handlers, 
	with configurable handler mappings, view resolution, locale, time zone and theme resolution as well as support for uploading files.
	
	Spring’s view resolution is extremely flexible. A Controller is typically responsible for preparing a model Map with data 
	and selecting a view name but it can also write directly to the response stream and complete the request. @Controller, @ResponseBody or just @Restcontroller
	
	View name resolution is highly configurable through file extension or Accept header content type negotiation, through bean names, 
	a properties file, or even a custom ViewResolver implementation. The model (the M in MVC) is a Map interface, which allows for 
	the complete abstraction of the view technology. You can integrate directly with template based rendering technologies such as JSP, 
	Velocity and Freemarker, or directly generate XML, JSON, Atom, and many other types of content. The model Map is simply transformed 
	into an appropriate format, such as JSP request attributes, a Velocity template model.
	
	
********************************
Spring Boot
********************************

Boot priorities:
	1. Commandline args
	2. JNDI
	3. Java System properties		- System.getProperty("path.separator");
	4. OS Environment variables		- System.getenv();
	5. Properties files				- application.properties
	6. @PropertySource				- @PropertySource("classpath:/com/myco/app.properties"), then in the config java file: @Autowired Environment env;
	7. Defaults

	
	
********************************
Spring React
********************************

Will be available from Spring Framework 5.

Another source of pain is that if we ever make a mistake and block in one of our Reactive callbacks, 
we will be holding up all requests on the same thread. With the servlet-based containers every request is isolated to a thread, 
and blocking doesn’t hold up other requests because they are be processed on different threads. 
Blocking all requests is still a recipe for trouble, but it only shows up as increased latency with roughly a constant factor per request. 
In the Reactive world, blocking a single request can lead to increased latency for all requests, 
and blocking all requests can bring a server to its knees because the extra layers of buffers and threads are not there to take up the slack.
	
	
	
	
	
********************************
Cloud: IaaS, PaaS, Clound Foundry
********************************

IaaS support: eIMS can be deployed on a cloud-based infrastructure. With this approach only the hardware is provided and scaling the 
	application means firing up more virtual machine instances, and after that each instance needs to be configured: 
	install an operating system, configure the connection to the datafarm, install, the Java runtime and all the necessary packages needed. 
	IaaS provides only the infrastructure (CPU, RAM, storage) but not the platform.
	
PaaS support: through Cloud Foundry which is an open source PaaS implementation. PaaS sits above the infrastructure (IaaS) and provides an 
	operating system for applications on top of that with all the tooling needed to scale the deployed applications. When scaling the application 
	is needed we can forget about installing new virtual machines and post-configurations. The application is the new unit of scale here, 
	we just say we need more instances of this component and the platform will automatically set things up.
	In a microservices world, where there are more components, we can even tell the system which component needs to be scaled up or down.
	What this means for the eIMS is that let’s say Alert Management microservice is having increased requests and struggles to serve them. 
	We can tell the platform that we need more instances of the Alert Management microservice and the platform will handle firing them up.
	Cloud Foundry is host-agnostic, meaning that it can run on VMWare, AWS, OpenStack, ...


	
********************************
Useful utils
********************************

FileCopyUtils	
org.springframework.util.FileSystemUtils
org.springframework.beans.BeanUtils
org.springframework.validation.ValidationUtils
DataSourceUtils (for JDBC), EntityManagerFactoryUtils (for JPA), SessionFactoryUtils, PersistenceManagerFactoryUtils (for JDO)


********************************
Streaming http requests
********************************

Return RxJava Observable


********************************
Eclipse multi maven project with Spring, TDPraktiker
********************************
1. workspace resolution works, eclipse sees, maven also sees the dependencies being in the same workspace: 
2. install the dependency into  the local repo with "mvn install" --> update the consumer project via "maven update" then voila, works!

TDPraktiker: parentPom/pom.xml: only for jenkins build
					
OAuth2 is basically a protocol that supports authorization workflows. What this means is that it gives you a way to ensure that 
a specific user has permissions to do something. That’s it. 
OAuth2 isn’t meant to do stuff like validate a user’s identity — that’s taken care of by an Authentication service. 
Authentication is when you validate a user’s identity (like asking for a username / password to log in), 
whereas authorization is when you check to see what permissions an existing user already has.
Just remember that OAuth2 is a protocol for authorization.



class Convert<M, R> {

	public R convert(M model, Class<R> aClass) {
		R result;
		try {
			result = aClass.newInstance();
			org.springframework.beans.BeanUtils.copyProperties(model, result);
			return result;
		} catch (InstantiationException | IllegalAccessException e) {
			e.printStackTrace();
		}
		return null;
	}
}