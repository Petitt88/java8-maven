Cloud Foundry: PaaS platform
BOSH: how you automate, install and congfigure a CF system (among other things, it does a lot of stuff)

	
	
Containers vs Virtual Machines:
	Application Storage Overhead
		- Virtual Machines: Each application workload runs on a separate virtual machine – which typically needs Gigabytes of OS overhead.
		- Containers: Containers can run in isolation on the same physical or virtual machine – in which one common OS is used for all containers. The Docker Engine overhead is pretty small – i.e. megabytes.
		
	Instantiation
		- Virtual Machines: Boot up time of both the OS and the application
		- Containers: Application instantiation time only – i.e. time to spin up Linux processes
	
	Resource Allocation
		- Virtual Machines: Generally rigid. Virtual CPU and Memory are typically pre-allocated to a VM and are hard to change post-provision – depending on the virtualization platform or cloud provider used.
		- Containers: Generally flexible. CPU and Memory maximum limits can be defined for containers if desired (using the cpu_shares and mem_limit parameters). By default, containers can continue to consume the resources available on the underlying machine. With HyperForm, the minimum limits for CPU and Memory can also be defined — allowing users to place application workloads on machines that have enough CPU and Memory resources. You can read more about this here: http://dchq.co/docker-compose.html#docker-nodejs.
	
Cloud Foundry vs Docker:
	- Docker is a technology for creating and running Linux "containers." A docker container for SpringBoot app will consist of a docker image, which will basically contain a filesystem with all the things needed to run your app (JVM, your source code, etc.), and docker container metadata, which tells the docker daemon how to run the app inside the image (e.g. what environment variables to set, what ports to expose, what commands to run, etc.). The docker daemon will use Linux features such as groups and kernel namespaces to run the container in isolation from other processes running on the host machine. Docker is somewhat low-level, in that you need to specify everything that goes into the image, and it runs arbitrary things, namely whatever you put into your image and tell it to run. The docker container that you get is very portable, so you can build, test, and run your docker container locally for development, and then ship that container to a production host that also has a docker daemon running on it, and be quite confident that you're getting the exact same thing.
	
	- Cloud Foundry works at a higher layer of abstraction, with applications being a first class concept. Cloud Foundry uses containerization technology similar to docker to build portable images and then run them, but it's an implementation detail and you don't need to specify all the details. In newer versions of Cloud Foundry, docker images will also be supported so you can specify the details if you want, but it also has a "buildpack" workflow, where it will automatically detect a Java application when you push your app and will know to include all the things necessary for the Java runtime when it builds the image.
	
	With Cloud Foundry, since applications and application management are first class concepts, and since it operates at a higher level, you get all sorts of things for free. For instance, you can easily scale your app horizontally (add instances), e.g. cf scale my_app -i 5 or vertically, cf scale my_app -m 2G (to set the allocated memory for each instance). You get streaming application logs: cf logs my_app. Cloud Foundry gives you a lot of fault tolerance for free, so if one of your application instances crashes, or the process running the application containers itself crashes (the thing that's similar to the docker daemon), or if the host VM that's running the container-running process dies, or the hardware cluster where that VM resides dies, Cloud Foundry will automatically bring your instances back up.

	The docker daemon is a single process you can run on any Linux machine. So if you're doing something small and simple, and you need to do most of the setup yourself, it can be easier to get up and running both locally and in development using docker. With docker it's also easier to have access and share the docker image you create, so once you've created an image, you can put it in a docker repository, and then you can run it on any other docker daemon. With Cloud Foundry, the built image is generally an implementation detail and you don't really have access to it, so for instance you couldn't extract that image and run it on another Cloud Foundry installation.

	There are various projects out there intended to make Cloud Foundry more accessible and easier to set up, while still giving you many of the benefits of a PaaS. Some of these projects also aim to allow you to combine using docker and the benefits of docker while also getting a lot of the PaaS benefits you get from Cloud Foundry.
	
	
Containers:
	Many view containers as virtual machines. They’re not. Well kind of not. A container is a virtual walled environment for your application. It’s literally a ‘container’ inside the host OS. Thus your application works like it is in it’s own self contained environment, but it’s actually sharing operating system resources of the host computer.  Because of this, containers are more resource efficient than full blown virtual machines. 
	
Docker:

	Dockerfile --> (docker build) --> image --> (docker run) --> container
																(docker stop, docker start)
					(docker pull) --> download ready-to-use image from Docker Hub

	Daily cmd commands (cli):
		docker --help
		docker version
		docker info - prints info about the host VM: OS, OS version, RAM, CPU, containers, running containers, docker root dir, ...
	
		docker pull [image_name]] - to pull existing image from Docker Hub
		docker build -t my_mongodb . - to create an image named "my_mongodb" from the Dockerfile script located in the same folder
			-t [name of image] - name of the iamge
			. - acting as a build-directory argument
			--file - name of the Dockerfile (Default is 'PATH/Dockerfile')
		docker run [image_name] - to create a new contaimer from the image (copies the image into a folder to the disk) 
			- the last string segment must be the name of the image!
			- this command can be run multiple times resulting in more instances (containers) created
			- but with this we would have to deal  with compley IDs instead of friendly names
			
			- docker run --name my-mongo_1 -d my_mongodb
				--name [container_instance_name]
				-d - detach, run the in background
			
			docker run -d -p 127.0.0.1:81:80 --name webserver nginx - the same as:
			docker run -d -p 81:80 --name webserver nginx
				-p - this binds port 80 of the container to port 81 on 127.0.0.1 of the host machine. In other words it publishes a oontainer port to a port of the host OS.
				The -p swtich CANNOT be used in Dockerfile scripts because that would be a security issue and only local administrators can set which port gets publish on the container to which port of the host OS. To avoid long "docker run" commands, consider using docker-compose: http://stackoverflow.com/questions/32740344/how-to-publish-ports-in-docker-files
					mywebserver:
					  image: nginx
					  ports:
						- 81:80
						
				since containers are isolated I can easily spin up another instace of the "nginx" image but this time binding to different port on the host OS to avoid port collision:
					docker run -d -p 82:80 --name webserver2 nginx
				
			docker run --expose 80 --name webserver nginx
				--expopse - this exposes port 80 of the container without publishing the port to the host system’s interfaces.
				
			docker run --name=config-server --publish=8888:8888 --volume=spring-cloud-config-repo:/var/lib/spring-cloud/config-repo config-server:latest
			
		docker start [container_id] - starts the container
	
		docker stop [container_id] - to stop the container
		docker rm [container_id] - to remove the container
		docker rmi [image_id] - to remove the image
		
		docker commit c3f279d17e0a  svendowideit/testimage:version3 
			- create a new image which name is "vendowideit/testimage", tag is "version3" using the container which id is "c3f279d17e0a"
		docker cp - copy files/folders from the containers filesystem to the host path
		
		docker search [string] - to search for images
		docker pull [image_name] - to download the image from Docker Hub
		docker push - to push image back to Docker Hub and share it with other folds
		
		docker images - list all images available
		docker ps - list running containers
		docker ps -- all - list all containers
		
		docker exec - run a command in a running container
			docker exec -it [container-id] bash - to be able 
				-i - keep STDIN open even if not attached
				-t - allocate a pseudo-TTY
				
		docker network inspector nat
			- to see what IP addresses the containers are running on
		
	Container, images location:
		- if using linux containers, the location is the MobyLinuxVM.vhdx that is automatically started using Hyper-V
			/var/lib/docker
		- if using windows containers, C:\ProgramData\Docker\ folder is the destination 
			there are "image", "containers", "swarm" folders though these ones contain only metadata (folder name is the identifier)
			"windowsfilter" folder contains the real container filesystem (pick one based on the identifier --> "Files" and there you see the installed filesystem (windows OS is shared with the host and linux is not supported), the libraries (php, inetpub iis) and your application
			
	Docker related commands (to be used in Dockerfile scripts)
		ADD 
			ADD <src>... <dest> 
			or ADD ["<src>",... "<dest>"] (this form is required for paths containing whitespace)
			
			The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>.
			The <dest> is an absolute path, or a path relative to WORKDIR, into which the source will be copied inside the destination container.
			
			ADD test relativeDir/          # adds "test" to `WORKDIR`/relativeDir/
			ADD test /absoluteDir/         # adds "test" to /absoluteDir/
			
		CMD
			CMD ["executable","param1","param2"] (exec form, this is the preferred form)
			CMD ["param1","param2"] (as default parameters to ENTRYPOINT)
			CMD command param1 param2 (shell form)
			
			There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect.
			The main purpose of a CMD is to provide defaults for an executing container. These defaults can include an executable, or they can omit the executable, in which case you must specify an ENTRYPOINT instruction as well.
			
			When used in the shell or exec formats, the CMD instruction sets the command to be executed when running the image.
			If you use the shell form of the CMD, then the <command> will execute in /bin/sh -c
			
		COPY
			COPY <src>... <dest>
			COPY ["<src>",... "<dest>"] (this form is required for paths containing whitespace)
			
			The COPY instruction copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>.
			
		ENV
			ENV <key> <value>
			ENV <key>=<value> ...
			
			The ENV instruction sets the environment variable <key> to the value <value>. This value will be in the environment of all “descendant” Dockerfile commands and can be replaced inline in many as well.
			The ENV instruction has two forms. The first form, ENV <key> <value>, will set a single variable to a value. The entire string after the first space will be treated as the <value> - including characters such as spaces and quotes.
			The second form, ENV <key>=<value> ..., allows for multiple variables to be set at one time. 
			
			ENV myName="John Doe" myDog=Rex\ The\ Dog \
				myCat=fluffy
			ENV myName John Doe
			ENV myDog Rex The Dog
			ENV myCat fluffy
			
		ENTRYPOINT
			ENTRYPOINT ["executable", "param1", "param2"] (exec form, preferred)
			ENTRYPOINT command param1 param2 (shell form)
			An ENTRYPOINT allows you to configure a container that will run as an executable.
			
		EXPOSE
			EXPOSE <port> [<port>...]
			
			The EXPOSE instruction informs Docker that the container listens on the specified network ports at runtime. EXPOSE does not make the ports of the container accessible to the host. To do that, you must use either the -p flag to publish a range of ports or the -P flag to publish all of the exposed ports. You can expose one port number and publish it externally under another number.
			
			This is used for communication between containers, but not with the host OS.
			
		FROM
			FROM <image>
			FROM <image>:<tag>
			FROM <image>@<digest>
			
			The FROM instruction sets the Base Image for subsequent instructions. As such, a valid Dockerfile must have FROM as its first instruction. The image can be any valid image – it is especially easy to start by pulling an image from the Public Repositories.
			
		LABEL
			LABEL <key>=<value> <key>=<value> <key>=<value> ...
			The LABEL instruction adds metadata to an image.
			
		MAINTAINER (deprecated)
			MAINTAINER <name>
			
			The MAINTAINER instruction sets the Author field of the generated images. The LABEL instruction is a much more flexible version of this and you should use it instead.
			
			LABEL maintainer "SvenDowideit@home.org.au"
			
		RUN
			RUN <command> (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)
			RUN ["executable", "param1", "param2"] (exec form)
			
			The RUN instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the Dockerfile.
			Layering RUN instructions and generating commits conforms to the core concepts of Docker where commits are cheap and containers can be created from any point in an image’s history, much like source control.
			The exec form makes it possible to avoid shell string munging, and to RUN commands using a base image that does not contain the specified shell executable.
			
		USER
			USER daemon
			The USER instruction sets the user name or UID to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile.
			
		VOLUME
			VOLUME ["/data"] - mounts the host's /var/lib/docker folder to the container's /data folder
			The VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers. The value can be a JSON array, VOLUME ["/var/log/"], or a plain string with multiple arguments, such as VOLUME /var/log or VOLUME /var/log /var/db.
			
		WORKDIR
			WORKDIR /path/to/workdir
			The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile. If the WORKDIR doesn’t exist, it will be created even if it’s not used in any subsequent Dockerfile instruction.

			It can be used multiple times in the one Dockerfile. If a relative path is provided, it will be relative to the path of the previous WORKDIR instruction. For example:
				WORKDIR /a
				WORKDIR b
				WORKDIR c
				RUN pwd
				The output of the final pwd command in this Dockerfile would be /a/b/c.
	
			
		Prefer ENTRYPOINT to CMD when building executable Docker image and you need a command always to be executed. Additionally use CMD if you need to provide extra default arguments that could be overwritten from command line when docker container runs.
		
			- RUN executes command(s) in a new layer and creates a new image. E.g., it is often used for installing software packages.
			- CMD sets default command and/or parameters, which can be overwritten from command line when docker container runs.
			- ENTRYPOINT configures a container that will run as an executable.
			
		EXPOSE vs -p (port)
			Basically, you have three options:
				- Neither specify EXPOSE nor -p.
				- Only specify EXPOSE.
				- Specify EXPOSE and -p.
				
			If you do not specify any of those, the service in the container will not be accessible from anywhere except from inside the container itself.
			If you EXPOSE a port, the service in the container is not accessible from outside Docker, but from inside other Docker containers. So this is good for inter-container communication.
			If you EXPOSE and -p a port, the service in the container is accessible from anywhere, even outside Docker.
			
		Shell and Exec forms
			All three instructions (RUN, CMD and ENTRYPOINT) can be specified in shell form or exec form.
			
			Shell form: <instruction> <command>
				RUN apt-get install python3  
				CMD echo "Hello world"  
				ENTRYPOINT echo "Hello world"  
				
				When instruction is executed in shell form it calls /bin/sh -c <command> under the hood and normal shell processing happens. For example, the following snippet in Dockerfile
					ENV name John Dow  
					ENTRYPOINT echo "Hello, $name"  
				when container runs as "docker run -it <image>" will produce output: Hello, John Dow  
				
			Exec form: <instruction> ["executable", "param1", "param2", ...], this is the preferred form for CMD and ENTRYPOINT instructions.
				RUN ["apt-get", "install", "python3"]  
				CMD ["/bin/echo", "Hello world"]  
				ENTRYPOINT ["/bin/echo", "Hello world"]
				
				When instruction is executed in exec form it calls executable directly, and shell processing does not happen. For example, the following snippet in Dockerfile
					ENV name John Dow  
					ENTRYPOINT ["/bin/echo", "Hello, $name"]  
				when container runs as "docker run -it <image>" will produce output: Hello, $name  
				
		
		
	Docker project (open-sourced by dotCloud in March '13) consists of several main parts (applications) and elements (used by these parts) which are all [mostly] built on top of already existing functionality, libraries and frameworks offered by the Linux kernel and third-parties (e.g. LXC, device-mapper, aufs etc.).

	Main Docker Parts
		1. docker daemon: used to manage docker (LXC) containers on the host it runs (this is the docker engine?)
		2. docker CLI: used to command and communicate with the docker daemon
		3. docker image index: a repository (public or private) for docker images
		
	Main Docker Elements
		1. docker containers: directories containing everything-your-application
		2. docker images: snapshots of containers or base OS (e.g. Ubuntu) images
		3. Dockerfiles: scripts automating the building process of images
		
	- An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files.

	- A container is a runtime instance of an image – what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so.

	- Containers run apps natively on the host machine’s kernel. They have better performance characteristics than virtual machines that only get virtual access to host resources through a hypervisor. Containers can get native access, each one running in a discrete process, taking no more memory than any other executable.
	
	- Virtual machines run guest operating systems – note the OS layer in each box. This is resource intensive, and the resulting disk image and application state is an entanglement of OS settings, system-installed dependencies, OS security patches, and other easy-to-lose, hard-to-replicate ephemera.
	
	- Containers can share a single kernel, and the only information that needs to be in a container image is the executable and its package dependencies, which never need to be installed on the host system. These processes run like native processes, and you can manage them individually by running commands like docker ps – just like you would run ps on Linux to see active processes. Finally, because they contain all their dependencies, there is no configuration entanglement; a containerized app “runs anywhere.”
		
	Each container is layered like an onion and each action taken within a container consists of putting another block (which actually translates to a simple change within the file system) on top of the previous one. And various tools and configurations make this set-up work in a harmonious way altogether (e.g. union file-system).

	Docker containers:
		Docker containers are basically directories which can be packed (e.g. tar-archived) like any other, then shared and run across various different machines and platforms (hosts). The only dependency is having the hosts tuned to run the containers (i.e. have docker installed). Containment here is obtained via Linux Containers (LXC). Containers are isolated.
		
		Docker containers have several main features.
			They allow:
				Application portability
				Isolating processes
				Prevention from tempering with the outside
				Managing resource consumption
				
			They do not allow:
				Messing with other processes
				Causing "dependency hell"
				Or not working on a different system
				Being vulnerable to attacks and abuse all system's resources
				
	Dockerfiles
		Each Dockerfile is a script, composed of various commands (instructions) and arguments listed successively to automatically perform actions on a base image in order to create (or form) a new one.
		
	.dockerignore file
		Before the docker CLI sends the context to the docker daemon, it looks for a file named .dockerignore in the root directory of the context. If this file exists, the CLI modifies the context to exclude files and directories that match patterns in it. This helps to avoid unnecessarily sending large or sensitive files and directories to the daemon and potentially adding them to images using ADD or COPY.
				
	Being based and depending on LXC (Linux containers), from a technical aspect, these containers are like a directory (but a shaped and formatted one). This allows portability and gradual builds of containers.
	
	Getting started on Linux:
		1. instal docker
		2. run the docker daemon: sudo docker -d &
		3. Using docker (via CLI) consists of passing it a chain of options and commands followed by arguments. Please note that docker needs sudo privileges in order to work.: sudo docker [option] [command] [arguments]

		
	Searching for images in the docker repository:
		docker search ubuntu
		docker search windows
	
	
	Committing changes to an image: docker commit [container ID] [image name]
		As you work with a container and continue to perform actions on it (e.g. download and install software, configure files etc.), to have it keep its state, you need to “commit”. Committing makes sure that everything continues from where they left next time you use one (i.e. an image).
		
		Then this image can be pushed into Docker Hub: docker push [username/image name] 
		Later on Dockerfile scripts can perform "FROM" this image after being pulled down (docker pull [image_name])
		
Docker Compose

	Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file (docker-compose.yml) to configure your application’s services. Then, using a single command, you create and start all the services from your configuration.
	
	Using Compose is basically a three-step process.
		1. Define your app’s environment with a Dockerfile so it can be reproduced anywhere.
		2. Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment.
		3. Lastly, run docker-compose up and Compose will start and run your entire app.
		
	Daily commands (cli):
		docker-compose --help
		docker-compose version
		docker-compose up - to start the images either from Docker Hub or build them from Dockerfile then start (Create and start containers)
			docker-compose up -d <-- to detach the terminal and run the services in the background
		docker-compose down - to stop then even remove the containers (brings down everything) (Stop and remove containers, networks, images, and volumes)
			docker-compose down --volumes - to remove the volumes as well
		docker-compose run - allows you to run one-off commands for your services
			For example, to see what environment variables are available to the "web" service: docker-compose run web env
			
		docker-compose build - build or rebuild services
		docker-compose bundle - generate a Docker bundle from the Compose file
		docker-compose images - list images
		docker-compose start - start services
		docker-compose stop - stop services
		docker-compose create - create services
		docker-compose rm - remove stopped containers
		docker-compose ps - list running containers
			docker-compose ps --all - list all containers
		docker-compose port - print the public port for a port binding
			
		docker-compose scale - sets the number of containers to run for a service. Numbers are specified as arguments in the form service=num.
			docker-compose scale web=2 worker=3 - will result in 2 running instaces (containers) of the "web" and  3 instances (containers) of the "worker" services. Note: another instace of the same container won't start if using port sharing because the ports would collide on the host OS (multiple containers will try to bind to the same port on the host).
		docker-compose exec [options] SERVICE COMMAND [ARGS...] - This is equivalent of docker exec. With this subcommand you can run arbitrary commands in your services. 
																  Commands are by default allocating a TTY, so you can do 	e.g. docker-compose exec web sh to get an interactive prompt.
			
	docker-compose related commands (to be used in docker-compose.yml files)
		config - check our build-file for syntax-errors
	
		build: . - use the current folder and look for "Dockerfile"
		
		build:
		  context: ./dir 						- context is a path to a directory containing a Dockerfile
		  dockerfile: Dockerfile-alternate 		- name of the Dockerfile which is not the default (ofc the default "Dockerfile" can be specified as well but it is pointless
		  
		build: ./dir
		image: webapp:tag - this will result in an image named webapp and tagged tag, built from ./dir
			without specifying the image and building from a Dockerfile (instead of using an image from the Docker Hub) the built image's name is going to be {folder_name_of_docker-compose_file}_{service_name}
		
		container_name - Specify a custom container name, rather than a generated default name.
			without specifying the container_name the default name of the contaimer is going to be {image_name}_1
		
		expose - expose ports without publishing them to the host machine - they’ll only be accessible to linked services. Only the internal port can be specified.
		
		image - Specify the image to start the container from. Can either be a repository/tag or a partial image ID.
				In this case the "build" command is not specified.
				
		ports - publishes ports on the container to the host OS so it can be reached from the host
				Either specify both ports (HOST:CONTAINER), or just the container port (a random host port will be chosen).
				docker ps - will display the running containers alongs with the port mappings
				
		volumes - Mount host paths or named volumes. Named volumes must be defined in the top-level volumes key.
				  If we make modifications into the mounted on the host OS, then we see changes immediately without having to rebuild the image.
				  
		command: VERY IMPORTANT: if specified, the CMD/ENTRYPOINT specified in the Dockerfile gets ignored! So this basically replaces the CMD/ENTRYPOINT. Has the same effect.
				 Override the default command (from the Dockerfile).
				  
		depends_on 
			express dependency between services, which has two effects:
				docker-compose up will start services in dependency order. In the following example, db and redis will be started before web.
				docker-compose up SERVICE will automatically include SERVICE’s dependencies. In the following example, docker-compose up web will also create and start db and redis.
								
				version: '3'
				services:
				  web:
					build: .
					depends_on:
					  - db
					  - redis
				  redis:
					image: redis
				  db:
					image: postgres
					
		networks - this is the identifier of the named networks to use. A given name-value must be listed in the networks section
		
			When you run docker-compose up, the following happens:
				1. A network called myapp_default is created.
				2. Each container created based on the orchestration of the "services" joins the network "myapp_default" under the container's name.
				3. These services can communicate with each other.
				
			This "networks" section allows us to define custom networks if some tweaking is necessary.
			
			You may be wondering why we didn’t do this on the back end service. The front end service needs to talk to that in order to retrieve data, so how is that working? This is where some magic happens. Docker provides a DNS system used to locate containers and docker compose sets up a Docker network for your defined services. All containers that are part of the docker-compose services definition are reachable by other containers on that network. This means that we don’t have to explicitly expose the back end port for the containers to communicate. As we’re not expecting to allow external systems to call the back end API it’s best to avoid exposing it’s port on the host.
		links
			link to containers in another service. Either specify both the service name and a link alias (SERVICE:ALIAS), or just the service name.
			
			This will create an internal network link between this service and the listed service. This service will be able to connect to the listed service, whereby the part before the colon specifies a service-name from the services section and the part after the colon specifies the hostname at which the service is listening on an exposed port
			
			version: '2'
			services:
				config-server:
					container_name: config-server
					build:
						context: .
						dockerfile: Dockerfile.server
					image: config-server:latest
					expose:
						- 8888
					networks:
						- spring-cloud-network
					volumes:
						- spring-cloud-config-repo:/var/lib/spring-cloud/config-repo
					logging:
						driver: json-file
				config-client:
					container_name: config-client
					build:
						context: .
						dockerfile: Dockerfile.client
					image: config-client:latest
					entrypoint: /opt/spring-cloud/bin/config-client-entrypoint.sh
					environment:
						SPRING_APPLICATION_JSON: \
						  '{"spring": {"cloud":  \
						  {"config": {"uri": "http://config-server:8888"}}}}'
					expose:
						- 8080
					ports:
						- 8080:8080
					networks:
						- spring-cloud-network
					links:
						- config-server:config-server
					depends_on:
						- config-server
					logging:
						driver: json-file
			networks:
				spring-cloud-network:
					driver: bridge
			volumes:
				spring-cloud-config-repo:
					external: true
		
		
	Example:
		version: '2'
		services:
		  web:
			build: .
			ports:
			 - "5000:5000"
			volumes:
			 - .:/code			# mount the host's current directory to the container's /code directory. Whenever we change something in the current dir that is added to the container (ADD) the changes are automatically populated without the need to do "docker-compose down" then "docker-compose up"
		  redis:
			image: "redis:alpine"
			
		This Compose file defines two services, web and redis. The web service:
		- Uses an image that’s built from the Dockerfile in the current directory.
		- Forwards the exposed port 5000 on the container to port 5000 on the host machine.
		- Mounts the project directory on the host to /code inside the container, allowing you to modify the code without having to rebuild the image.
		The redis service uses a public Redis image pulled from the Docker Hub registry.
		
		Because the application code is mounted into the container using a volume, you can make changes to its code and see the changes instantly, without having to rebuild the image.
			1. Change the greeting in app.py and save it. For example: return 'Hello from Docker! I have been seen {} times.\n'.format(count)
			2. Refresh the app in your browser. The greeting should be updated, and the counter should still be incrementing.
			
		As with docker run, options specified in the Dockerfile (e.g., CMD, EXPOSE, VOLUME, ENV) are respected by default - you don’t need to specify them again in docker-compose.yml.
		
	Example 2:
		It’s time to begin building an app the Docker way. We’ll start at the bottom of the hierarchy of such an app, which is a container, which we cover on this page. Above this level is a service, which defines how containers behave in production, covered in Part 3. Finally, at the top level is the stack, defining the interactions of all the services, covered in Part 5.
			- Stack
			- Services
			- Container (you are here)
			
		Dockerfile will define what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you have to map ports to the outside world, and be specific about what files you want to “copy in” to that environment. However, after doing that, you can expect that the build of your app defined in this Dockerfile will behave exactly the same wherever it runs.
		
		A service really just means, “containers in production.” A service only runs one image, but it codifies the way that image runs – what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.
		
		A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production.
		The example above is meant to be used in production (contains the deploy settings) so that use it with "docker stack deploy" instead of "docker-compose". 
		Note: the latter does not know about the "deploy" settings: defining the running instances, maximum used computer resources, etc. "docker-compose" would simply just throw an error when feeding it with the below docker-compose.yml example file.
			version: "3"
			services:
			  web:
				image: username/repository:tag
				deploy:
				  replicas: 5
				  resources:
					limits:
					  cpus: "0.1"
					  memory: 50M
				  restart_policy:
					condition: on-failure
				ports:
				  - "80:80"
				networks:
				  - webnet
			networks:
			  webnet:
				
			- Run five instances of the image we uploaded in step 2 as a service called web, limiting each one to use, at most, 10% of the CPU (across all cores), and 50MB of RAM.
			- Immediately restart containers if one fails.
			- Map port 80 on the host to web’s port 80.
			- Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves will publish to web’s port 80 at an ephemeral port.)
			- Define the webnet network with the default settings (which is a load-balanced overlay network).

		
docker vs docker-compose
	The docker cli is used when managing individual containers on a docker engine. It is the client command line to access the docker daemon api.

	The docker-compose cli can be used to manage a multi-container application. It also moves many of the options you would enter on the "docker run ..." cli into the docker-compose.yml file for easier reuse. It works as a front end "script" on top of the same docker api used by docker, so you can do everything docker-compose does with docker commands along with a lot of shell scripting. See this documentation on docker-compose for more details.
	
	Update for Swarm Mode

		Since this answer was posted, docker has added a second use of docker-compose.yml files. Starting with the version 3 yml format and docker 1.13, you can use the yml with docker-compose and also define a stack in docker's swarm mode. To do the latter you need to use docker stack deploy -c docker-compose.yml $stack_name instead of docker-compose up and then manage the stack with docker commands instead of docker-compose commands. The mapping is a one for one between the two uses:

		- Compose Project -> Swarm Stack: A group of services for a specific purpose
		- Compose Service -> Swarm Service: One image and it's configuration, possibly scaled up.
		- Compose Container -> Swarm Task: A single container in a service
		
		docker swarm init - to enable swarm mode and make your current machine a swarm manager
		docker stack deploy -c docker-compose.deploy.yml getstartedlab - run the app with the name "getstartedlab"
		docker stack ps getstartedlab - list the running containers
			You can scale the app by changing the replicas value in docker-compose.yml, saving the change, and re-running the docker stack deploy command:	docker stack deploy -c docker-compose.deploy.yml getstartedlab
		docker stack rm getstartedlab - take down the app
		docker swarm leave - to leave the swarm as a worker
		docker swarm leave --force - to leave the swarm as a manager (manager creates the swarm)

	Commands:
		docker swarm init - to enable swarm mode and make your current machine a swarm manager
		docker swarm join - on other machines to have them join the swarm as a worker
		
	docker-machine - create a couple of virtual machines using our node management tool
	docker-machine create -d hyperv --hyperv-virtual-switch "myswitch" myvm1
	docker-machine ssh - you can send commands to your VMs

	A swarm is a group of machines that are running Docker and have been joined into a cluster. After that has happened, you continue to run the Docker commands you’re used to, but now they are executed on a cluster by a swarm manager. The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as nodes.
	
	Up until now you have been using Docker in a single-host mode on your local machine. But Docker also can be switched into swarm mode, and that’s what enables the use of swarms. Enabling swarm mode instantly makes the current machine a swarm manager. From then on, Docker will run the commands you execute on the swarm you’re managing, rather than just on the current machine.
	
	A swarm is made up of multiple nodes, which can be either physical or virtual machines. The basic concept is simple enough: run "docker swarm init" to enable swarm mode and make your current machine a swarm manager, then run "docker swarm join" on other machines to have them join the swarm as a worker. 
	
	
	In part 4, you learned how to set up a swarm, which is a cluster of machines running Docker, and deployed an application to it, with containers running in concert on multiple machines.

	Here in part 5, you’ll reach the top of the hierarchy of distributed applications: the stack. A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. A single stack is capable of defining and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks).

	Some good news is, you have technically been working with stacks since part 3, when you created a Compose file and used "docker stack deploy". But that was a single service stack running on a single host, which is not usually what takes place in production. Here, you’re going to take what you’ve learned and make multiple services relate to each other, and run them on multiple machines.
	
Multi stage builds:
	The multi-stage build allows using multiple FROM commands in the same Dockerfile. The last FROM command produces the final Docker image, all other images are intermediate images (no final Docker image is produced, but all layers are cached).
	The FROM syntax also supports AS keyword. Use AS keyword to give the current image a logical name and reference to it later by this name.
	To copy files from intermediate images use COPY --from=<image_AS_name|image_number>, where number starts from 0 (but better to use logical name through AS keyword).
	
		# ---- Base Node ----
		FROM alpine:3.5 AS base
		# install node
		RUN apk add --no-cache nodejs-npm tini
		# set working directory
		WORKDIR /root/chat
		# Set tini as entrypoint
		ENTRYPOINT ["/sbin/tini", "--"]
		# copy project file
		COPY package.json .
		 
		#
		# ---- Dependencies ----
		FROM base AS dependencies
		# install node packages
		RUN npm set progress=false && npm config set depth 0
		RUN npm install --only=production 
		# copy production node_modules aside
		RUN cp -R node_modules prod_node_modules
		# install ALL node_modules, including 'devDependencies'
		RUN npm install
		 
		#
		# ---- Test ----
		# run linters, setup and tests
		FROM dependencies AS test
		COPY . .
		RUN  npm run lint && npm run setup && npm run test
		 
		#
		# ---- Release ----
		FROM base AS release
		# copy production node_modules
		COPY --from=dependencies /root/chat/prod_node_modules ./node_modules
		# copy app sources
		COPY . .
		# expose port and define CMD
		EXPOSE 5000
		CMD npm run start
		
		- The above Dockerfile creates 3 intermediate Docker images and single release Docker image (the final FROM).
		- First image FROM alpine:3.5 AS bas – is a base Node image with: node, npm, tini (init app) and package.json
		- Second image FROM base AS dependencies – contains all node modules from dependencies and devDependencies with additional copy of dependencies required for final image only
		- Third image FROM dependencies AS test – runs linters, setup and tests (with mocha); if this run command fail not final image is produced
		- The final image FROM base AS release – is a base Node image with application code and all node modules from dependencies

Terminologies:
	
	docker images: 
		Snapshots of containers or base OS (e.g. Ubuntu) images. An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files.
		
	docker containers: 
		Directories containing everything-your-application. A container is a runtime instance of an image – what the image becomes in memory when actually executed. Containers run apps natively on the host machine’s kernel. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. EXPOSE is used to expose ports to other containers, and "-p" flag or docker-compose.yaml's "port" is used to publish ports to the host OS.
		
	Dockerfiles:
		Scripts automating the building process of images.
		
	Compose:
		Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file (docker-compose.yml) to configure your application’s services. Then, using a single command, you create and start all the services from your configuration.
		
	Service: 
		defines how a container (a single container) behaves in production. A service really just means, “containers in production.” A service only runs one image, but it codifies the way that image runs – what ports it should use, what volumes (map to host OS's foler(s)), how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.
	
	Stack: 
		is a group of interrelated services that share dependencies, and can be orchestrated and scaled together.
	
	Swarm: 
		is a cluster of machines running Docker, and deployed an application to it, with containers running in concert on multiple machines.
		
Usages:
	To use it with docker:
		docker build -t webpythonredis_web .	- creates the image named "webpythonredis_web" from the Dockerfile located in the same folder
		docker run -p 5000:80 -d --name web_1 webpythonredis_web
		docker stop web_1
		docker start web_1
		docker ps
		docker rm web_1
		docker ps -a
		docker rmi webpythonredis_web
	
	To use it with docker-compose:
		docker-compose up - creates the images (if they do not exist already) and starts the containers from the images
			docker-compose up --build (build images before starting containers)
		docker-compose ps - list the containers created by the docker-compose file
		docker-compose scale redis=4
		docker-compose down - stops the containers and removes them (basically this is a "stop" and "rm" command in one)
			docker-compose down --rmi all (remove all images used by any service)
		docker-compose images - list the images created by the docker-compose file
		docker-compose start - starts the containers
		docker-compose stop - stops the containers
		docker-compose rm - removes the containers

	To use it with docker in production (deploy):
		docker swarm init - to enable swarm mode and make your current machine a swarm manager
		docker stack deploy -c docker-compose.deploy.yml getstartedlab - run the app with the name "getstartedlab"
		docker stack ps getstartedlab - list the running containers inside "getstartedlab" app
			You can scale the app by changing the replicas value in docker-compose.yml, saving the change, and re-running the docker stack deploy command:	docker stack deploy -c docker-compose.deploy.yml getstartedlab
		docker stack rm getstartedlab - take down the app
		docker swarm leave --force - to leave the swarm as a manager (manager creates the swarm)