**********Java***********

ClassLoaders:

There are three types of built-in Class Loaders in Java:
1. Bootstrap Class Loader – It loads JDK internal classes, typically loads rt.jar and other core classes for example java.lang.* package classes
2. Extensions Class Loader – It loads classes from the JDK extensions directory, usually $JAVA_HOME/lib/ext directory.
3. System Class Loader – It loads classes from the current classpath that can be set while invoking a program using -cp or -classpath command line options.

We use a custom classloader when we need to extend how the JVM loads the classes. By default it loads from the -classpath (from the folder of the project).
But in some cases we may want to load a class from a database or from a remote resource (through http!).

The flow of "loadClass()" is as follows:

1. Verify class name.
2. Check to see if the class requested has already been loaded.
3. Check to see if the class is a "system" class.
4. Attempt to fetch the class from the parent class loader
5. Attempt to fetch the class from this class loader's repository.
6. Define the class for the VM.
7. Resolve the class.
8. Return the class to the caller.

Always load the classes once. It's also important to keep a cache because the loadClass() method is called recursively when a class is
being resolved, and you will need to return the cached result rather than chase it down for another copy.

Classpath: contains folders (like src/main/java) and jar files. A java class is found like this:
 - if a jar contains it, it is loaded from there
 - if not, the JVM concatenates the folder path from the classpath with the "import ..." statement located in the class file. 
   The resulting path must pont to the .class file.
   
   
   
 **********Eclipse**********
 
 The build path:
	contains folders, that are part of the classpath along with .jar libraries - individual jars, maven/gradle jars.
	These folders are tipically: src/main/java, src/main/resources, src/test/java. The order matters, the classloader tries the src/main/java first.
		Order can be changed in right click --> Properties --> Java Build Path --> Order and Export
		
		
Facets: this tells eclipse what our project is capable of. Right click --> Properties --> Project facets.
	Only those projects can be added for example to Tomcat that has
		- Java facet
		- Dynamic Web Module facet: if the project has this the Properties will show the "Deployment Assembly" menu which tells eclipse where to put certain
			folders (like /src/main/java) in the output .war file. Usually there is a "WebContent" folder as well located in /src/main/WebContent, however Spring does not require this.
			Only old-school web archetype projects are scaffolded with this folder (it is for holding the static files: html, css, js. Also the web.xml, other necessary config xml files).
			If no web.xml was added, then add it manually: in Project Explorer: Deployment Descriptor right click --> Generate Deployment Descriptor Stub
			
			Also:
				- this facet makes eclipse display our application on the popup shown when trying to add our application to the ones that get started when Tomcat starts: Servers tab --> Tomcat --> Right click --> "Add and Remove..." - now out application is displayed
				- this faces makes eclipse able to run our application on server: On the project --> Right click --> Run as --> Run on Server. Now our application starts.
			
			This facet also adds the web.xml deployment descriptor. This is where filters/servlets FilterConfigs, ServletConfigs can be specified using 2.5 servlet-container.
			3.0+ servlet-containers support annotation-based Servlet, Filters and their configs, init-params without the need for a web.xml.
			In maven the fail on missing web.xml can be turned off:
				<build>
					<plugins>
						<plugin>
							<groupId>org.apache.maven.plugins</groupId>
							<artifactId>maven-war-plugin</artifactId>
							<version>2.6</version>
							<configuration>
								<failOnMissingWebXml>false</failOnMissingWebXml>
							</configuration>
						</plugin>
					</plugins>
				</build>




**********Maven**********

a plugin is a collection of goals with a general common purpose

mvn archetype:generate - plugin:goal: execute the "generate" goal of the "archetype plugin"

mvn package - Rather than a goal, this is a phase
A phase is a step in the build lifecycle, which is an ordered sequence of phases. A phase consists of plugin goals.
When a phase is given, Maven will execute every phase in the sequence up to and including the one defined. Every goal in these cases is executed.
For example, if we execute the compile phase, the phases that actually get executed are:

mvn -DskipTests=true clean install <-- to excute the "clean" phase of the "clean" lifecycle then the "build" lifecycle's "install" phase but skip the preceeding "test" phase

mvn spring-boot:run: to run a spring boot project (pom.xml is required ofc)
mvn spring-boot:run --debug

validate
generate-sources
process-sources
generate-resources
process-resources
compile

Lifecycles:
 - clean: cleans up artifacts created by prior builds
 - build: (and its default phases are:)	validate: validate the project is correct and all necessary information is available
										compile: compile the source code of the project
										test: test the compiled source code using a suitable unit testing framework. These tests should not require the code be packaged or deployed
										package: take the compiled code and package it in its distributable format, such as a JAR.
										integration-test: process and deploy the package if necessary into an environment where integration tests can be run
										verify: run any checks to verify the package is valid and meets quality criteria
										install: install the package into the local repository, for use as a dependency in other projects locally
										deploy: done in an integration or release environment, copies the final package to the remote repository for sharing with other developers and projects.
- site: generates site documentation for this project

An interesting thing to note is that phases and goals may be executed in sequence:
	mvn clean dependency:copy-dependencies package - This command will clean the project, copy dependencies, and package the project (executing all phases up to package, of course).

A Build Lifecycle is Made Up of Phases
A Build Phase is Made Up of Plugin Goals


To install an external jar into a project-repository:
mvn install:install-file -DlocalRepositoryPath=repo -DcreateChecksum=true -Dpackaging=jar -Dfile="lib/overall-lib-0.0.1.jar" -DgroupId=overall-lib -DartifactId=overall-lib -Dversion="0.0.1" -e

When creating a maven multi-project app (parent's packaging is "pom") it is very important to always build the parent pom.
That will build all of the modules individually and resolve the dependencies (ensuring the correct order of the build of projects).
As soon as a modules starts depending on another, that module cannot be built from its pom. The parent pom will be the only one that can build it from that point on.


Maven plugins (build and reporting) are configured by specifying a <configuration> element where the child elements of the <configuration> element 
are mapped to fields, or setters, inside your Mojo (remember that a plug-in consists of one or more Mojos where a Mojo maps to a goal). 
Say, for example, we had a Mojo that performed a query against a particular URL, with a specified timeout and list of options.
https://maven.apache.org/guides/mini/guide-configuring-plugins.html


How do you know Jackson 2 is on the classpath? 
Either run `mvn dependency:tree` or './gradlew dependencies' and you'll get a detailed tree of dependencies which shows Jackson 2.x. 
You can also see that it comes from spring-boot-starter-web.

To update dependencies shown in eclipse: right click on the project --> Maven --> Update Project... (Maven tends to do this on his own but not always :-()



**********Gradle**********

build.gradle file
The eclipse plugins adds 2 nice views: Gradle Executions and Gradle Tasks to be able to run the desired gradle task without:
	1. going to the command line
	2. the need to use the Run Configurations... window where we can add a new "Gradle Project"

gradle --help: to display the help window
gradle tasks: to display the available tasks (plugins might add tasks, so does the "java" plugin)
gradle <task>: to run a task

gradle clean: deletes the build directory
gradle jar: assemble a jar achrive containing the main classes
gradle javadoc: generates javadoc
gradle build: assembles and tests the project
gradle check: run all checks
gradle test: run the unit tests

gradle bootRun: to run a spring-boot project (build.gradle required ofc)

gradle clean jar: to run the "clean" and after that the "jar" tasks - java plugins adds them

https://docs.gradle.org/current/userguide/tutorial_gradle_command_line.html
Example multiple tasks:
	task compile << {
		println 'compiling source'
	}

	task compileTest(dependsOn: compile) << {
		println 'compiling unit tests'
	}

	task test(dependsOn: [compile, compileTest]) << {
		println 'running unit tests'
	}

	task dist(dependsOn: [compile, test]) << {
		println 'building the distribution'
	}

	
A little explanation about the build.gradle file's structure:

- there are plugins that expose configurations and we can specify configuration sections to adjust them:
build.gradle:

	eclipse {
		classpath {
			 containers.remove('org.eclipse.jdt.launching.JRE_CONTAINER')
			 containers 'org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-1.8'
		}
	}
	sonarqube {
		properties {
			property "sonar.projectVersion", "1.0"
			property "sonar.jacoco.reportPath", "${buildDir}/jacoco/test.exec"
			property "sonar.java.source", "1.8"
			property "sonar.java.target", "1.8"
		}
	} 
	
	The "eclipse" and "sonarqube" are config sections exposed by the corresponding plugins:
		plugins{
			id "org.sonarqube" version "1.1"
		}

		apply plugin: 'java'
		apply plugin: 'eclipse'
		apply plugin: 'spring-boot' 
		apply plugin: 'jacoco'
	
	Dependencies:
		dependencies {
			// Mysql and Mssql connection
			compile('mysql:mysql-connector-java:5.1.38')
			compile files('libs/sqljdbc4-4.2.jar')
			
			compile project(':VMCPriceDetector')
			
			// Mybatis
			compile("org.mybatis.spring.boot:mybatis-spring-boot-starter:1.1.1")
			
			// RxJava 
			compile("io.reactivex:rxjava:1.1.7")	// maven's compile
			
			providedRuntime("org.springframework.boot:spring-boot-starter-tomcat")	// maven's provided
			runtime("...")	// maven's runtime
			
			testCompile("org.springframework.boot:spring-boot-starter-test") 
			testCompile("org.hsqldb:hsqldb:2.3.4")
		}
		
		// hooking into the "test" task: this method will be called before the "test" task itself
		// note: chaning it to for instance "test2" would make the build instantly fail since there is no "test2" function defined before 
		test {
			println "- I'm the largest animal that has ever lived on this planet."
		}
		
settings.gradle:
	include ':VMCPriceDetector'
	project(':VMCPriceDetector').projectDir = new File(settingsDir, '../VMCPriceDetector')
		
		
	A little more on dependencies: after modifying the dependencies, in Eclipse a refresh is necessary to make Eclipse update the jars displayed 
		in "Project and External Dependencies" library:
		
		right click on the project --> Gradle --> Refresh Gradle Project (this is similar to Maven's Update Project...)
		
How to build multiple projects in gradle (include dependencies and their transitive dependencies into the build output): 
	https://docs.gradle.org/current/userguide/multi_project_builds.html
		
		

**********Tomcat**********

tomcat-users.xml:
	<role rolename="admin-gui"/>
	<role rolename="manager-gui"/>
	<user username="admin" password="admin" roles="admin-gui,manager-gui"/>

	Specifies the users and their roles. Tomcat comes with default roles. For example the "manager-gui" role is required to be able to access the "Manager app" (http://localhost:8080/manager/html)
	
	
server.xml

	the port Tomcat gets started on can be changed here.
	
Deploy:
	war files can be deployed in two ways:
	
		1. copy the .war into the "webapps" folder. Context path will be the war's name.
		2. Launch tomcat and use the "Manager app" to deploy a war. The user can optionally change the context path here.
			In order to be able to use the "Manager app" a user with "manager-gui" role must be added to the tomcat-users.xml file, like this: <user username="admin" password="admin" roles="tomcat,manager-gui"/>
			
To run Tomcat:

	/bin/startup.bat	<-- runs tomcat

	Note: running Tomcat from Eclipse does not allow us to use the default apps that come with Tomcat (like the manager app)
	Double-clicking on the Tomcat server in the "Servers" view in Eclispe allows us to change some settings (like the port on the "Overview" tab and the context path of the deployed applications on the "Modules" tab), 
		but THIS HAS NO EFFECT on the real server.xml and other files which are taken into consideration when starting Tomcat from the /bin folder instead of using Eclipse. So it has no effect on production environment.



**********Servlet**********

Request, Response objects - created per access
Servlet itself: not per access, shared accross different threads (1 thread / user)
HttpSession: 1 session object / user, machine - user specific
ServletContext - shared accross users (application-level) - 1 instance per application

GenericService	- init(ServletConfig) - for the very 1st request only
	|
HTTPServlet		- servlet() - at every request
	|
MyServlet		- doGet, doPost (at every request)


Filter interface:

void init(FilterConfig paramFilterConfig) – When container initializes the Filter, this is the method that gets invoked. This method is called only once in the lifecycle of filter and we should initialize any resources in this method. FilterConfig is used by container to provide init parameters and servlet context object to the Filter. We can throw ServletException in this method.
doFilter(ServletRequest paramServletRequest, ServletResponse paramServletResponse, FilterChain paramFilterChain) – This is the method invoked every time by container when it has to apply filter to a resource. Container provides request and response object references to filter as argument. FilterChain is used to invoke the next filter in the chain. This is a great example of Chain of Responsibility Pattern.
void destroy() – When container offloads the Filter instance, it invokes the destroy() method. This is the method where we can close any resources opened by filter. This method is called only once in the lifetime of filter.

I can listen to events:
- ServletContextListener
- ServletContextAttributeListener
- HttpSessionListener
- HttpSessionAttributeListener




**********JSP***********

7.1 What Are Custom Tags?
	Custom tags, also known as tag extensions, are JSP elements that allow custom logic and output provided by other Java components to be inserted into JSP pages. 
	The logic provided through a custom tag is implemented by a Java object known as a tag handler. When OC4J encounters a custom tag in a JSP during translation, it generates code to obtain and 
	interact with the tag handler. Custom tags are included in a JSP page using XML syntax. Tags may or may not contain a body. Tags can also contain XML attributes that match properties in the corresponding tag handler.

With the advent of JSP 2.0, you now have two options for creating custom tags:

Tag handlers
	Tags that require the creation of tag handler classes come in two types: Classic and simple.
	Classic tag handlers have been available since JSP 1.1. Classic tags are considered somewhat cumbersome to write, in part because of the complexity of the Java interfaces used to implement each tag's corresponding tag handler class. They are also dependent on Java expressions for dynamic attribute values. However, these tag handlers are the only option if Java scriplets or expressions must be used in the tag body
	Simple tag handlers are new in JSP 2.0, and offer a much simpler lifecycle and interface than classic tag handlers. Tag bodies accept JSP expression language (EL) expressions, allowing completely script-free tag development.

Tag files
	Also new in JSP 2.0, tag files are revolutionary in that they allow tag libraries to be implemented completely in JSP or XML syntax, without the need to create and compile tag handler classes. Instead, tag files are translated into simple tag handlers by the OC4J JSP container and then compiled. Because of their ease of implementation, tag files offer an attractive alternative to writing tag handlers.

A tag file is a source file that contains a fragment of JSP code that is reusable as a custom tag. Tag files allow you to create custom tags using JSP syntax. 
Just as a JSP page gets translated into a servlet class and then compiled, a tag file gets translated into a tag handler and then compiled.


<%@ include file="header.html" %>
Static: adds the content from the value of the file attribute to the current page at translation time. 
The directive was originally intended for static layout templates, like HTML headers.

<jsp:include page="header.jsp" />
Dynamic: adds the content from the value of the page attribute to the current page at request time. 
Was intended more for dynamic content coming from JSPs.

In the latter case we can specify parameters as well:
<jsp:include page="navMenu.jsp" >
    <jsp:param name="param1" value="menu" />
</jsp:include>
${param.param1} (preferable) or request.getParameter("param1")




********Streams*********

The parallel streams use the default ForkJoinPool which by default has one less threads as you have processors, as returned by Runtime.getRuntime().availableProcessors() (so parallel streams use all your processors because they also use the main thread):
For applications that require separate or custom pools, a ForkJoinPool may be constructed with a given target parallelism level; by default, equal to the number of available processors.

Streams should be used with high caution when processing intensive computation tasks. In particular, by default, all streams will use the same ForkJoinPool, configured to use as many threads as there are cores in the computer on which the program is running.
If evaluation of one parallel stream results in a very long running task, this may be split into as many long running sub-tasks that will be distributed to each thread in the pool. From there, no other parallel stream can be processed because all threads will be occupied. So, for computation intensive stream evaluation, one should always use a specific ForkJoinPool in order not to block other streams.

List<SomeClass> list = // A list of objects
Stream<SomeClass> stream = list.parallelStream().map(this::veryLongProcessing);
Callable<List<Integer>> task = () -> stream.collect(toList());
ForkJoinPool forkJoinPool = new ForkJoinPool(4);
List<SomeClass> newList = forkJoinPool.submit(task).get();




********Java generics*********
At runtime java forgets its generic information for instance variables. But it retains that information for subclasses!

List<String> x = new ArrayList<>(); - type information gets lost!
	List<String> x = new ArrayList<>();
	Class<? extends List> clazz = x.getClass();
	ParameterizedType type = (ParameterizedType) clazz.getGenericSuperclass();
	String name = type.getTypeName();
	System.out.println(name);	// prints out java.util.AbstractList<E>...

List<String> x = new ArrayList<String>() {}; - type information is retained due to we create a generic anonymous subclass of List<String> with no overrides!
	List<String> x = new ArrayList<String>() {};
	Class<? extends List> clazz = x.getClass();
	ParameterizedType type = (ParameterizedType) clazz.getGenericSuperclass();
	String name = type.getTypeName();
	System.out.println(name);	// prints out String!
	
	This is called the "Type token pattern" - the Spring implementation is ParameterizedTypeReference<T>
	

And by the way!
Generic information is kept for declared fields (so not for the instance but for the declaration), constructor parameters, method parameters and return types.
Type information is also preserved for extends and implements clauses.
So the generic information can be acquired through reflection:

	public class MyClass {
	
		private List<Integer> intList;
		
		private void testThisIsTrue() throws NoSuchFieldException, SecurityException {
			
			System.out.println(this.intList.getClass().getGenericSuperclass().getTypeName()); 					// prints java.util.AbstractList<E>
			System.out.println(this.getClass().getDeclaredField("intList").getGenericType().getTypeName());		// prints java.util.List<java.lang.Integer>
		}
	
	}
	
	
	
********Static imports*********

We can import static members from classes which allows us to use the member without the class qualification:

	import static hu.regens.edgemicro.feature.validation.Building.trySome;
	
	trySome();	// - in action
	
The static import declaration is analogous to the normal import declaration. Where the normal import declaration imports classes from packages, 
allowing them to be used without package qualification, the static import declaration imports static members from classes, 
allowing them to be used without class qualification.




**********TODO**********

1. read more JSP resources:
	- apache tiles	- check

2. JAX-RS, JAX-WS (both with and without Maven) - check

3. JDBC, JPA, Hibernate, EclipseLink examples - check

4. Spring - check

5. Unit test, jUnit, Mockito