1. The runtime version is determined by the starting project. No matter what the runtime of the other referenced dlls are, they will use the same as the starting project.
2. Similarly, only the starting app's config is taken into consideration.

Assembly loading process:

	It is based on strong name, the CLR uses the strong name of the assembly to load it
		strong name: assembly name + version + optional culture + public key of the digital signature
	1. the CLR checks whether the assembly has been loaded
	2. if not, checks the GAC that belongs to the starting app's runtime version (v2 or v4)
			GAC is located in C:\Windows\Microsoft.NET\assembly
	3. if not found in the GAC, probably probes the paths specified in the PATH environment variable
	4. if not found, tries in the same folder where the app is running
		this is because of the root web.config: (C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config\ setting:
		<system.web> <compilation> <assemblies> <add assembly="*" /> </assemblies> </compilation> </system.web>
		
	Once a dll is loaded, it cannot be loaded again with another version. So only one version of a dll can be loaded.
	What happens when a component requires for instance v1.0 but our code depends on v1.1? In this case that dll wins which gets loaded first.
	If it is ours the app will use v1.1, otherwise v1.0. To overcome this and make sure no matter which dll is loaded first and the v1.1 is going to be used anyway,
	we can add assemlby redirects into our web.config:
		<dependentAssembly>
			<assemblyIdentity name="Super.Component" publicKeyToken="31bf3856ad364e35" />
			<bindingRedirect oldVersion="0.0.0.0-1.0.0.0" newVersion="1.1.0.0" />
		</dependentAssembly>
	
	
machine.config:

	Contains machine level settings.
	The Machine.config file contains the ASP.NET schema for all of the Web applications on the server. This file is at the top of the configuration merge hierarchy.
	
	location for the v4 runtime:
		C:\Windows\Microsoft.NET\Framework\v4.0.30319\Config
		C:\Windows\Microsoft.NET\Framework64\v4.0.30319\Config
		
	location for the v2 runtime:
		C:\Windows\Microsoft.NET\Framework\v2.0.50727\CONFIG
		C:\Windows\Microsoft.NET\Framework64\v2.0.50727\CONFIG
	
good to know:
	1. certain apps register their providers, config sections, etc. in the machine.config. It is good to check it over time.
	2. Also it is a good practice to in the web.config or app.config place a <clear /> tag in whatever provider section.
	3. The best approuch is to tell the installer if possible (for example to the Oracle client or to the MySql when installing the providers) not to include machine level settings -->
		--> machine.config won't get polluted with pre-registered providers like this:
			<runtime>
				<assemblyBinding xmlns="urn:schemas-microsoft-com:asm.v1">
				  <dependentAssembly xmlns="urn:schemas-microsoft-com:asm.v1">
					<assemblyIdentity name="MySql.Data" publicKeyToken="c5687fc88969c44d" culture="neutral" />
					<bindingRedirect oldVersion="6.7.4.0" newVersion="6.9.9.0" />
				  </dependentAssembly>
				  <dependentAssembly xmlns="urn:schemas-microsoft-com:asm.v1">
					<assemblyIdentity name="MySql.Data.Entity" publicKeyToken="c5687fc88969c44d" culture="neutral" />
					<bindingRedirect oldVersion="6.7.4.0" newVersion="6.9.9.0" />
				  </dependentAssembly>
				  <dependentAssembly xmlns="urn:schemas-microsoft-com:asm.v1">
					<assemblyIdentity name="MySql.Web" publicKeyToken="c5687fc88969c44d" culture="neutral" />
					<bindingRedirect oldVersion="6.7.4.0" newVersion="6.9.9.0" />
				  </dependentAssembly>
				</assemblyBinding>
			</runtime>
			<DbProviderFactories>
				<add name="MySQL Data Provider" invariant="MySql.Data.MySqlClient" description=".Net Framework Data Provider for MySQL" type="MySql.Data.MySqlClient.MySqlClientFactory, MySql.Data, Version=6.9.9.0, 			Culture=neutral, PublicKeyToken=c5687fc88969c44d" />
			</DbProviderFactories>
		And so on...
	4. use client providers from nuget if available:
		- for example we do not have to install the ODP.NET (Oracle Data Provider for .NET) which is several hundred megabytes big (http://www.oracle.com/technetwork/topics/dotnet/index-085163.html)
		- instead we could install just 2 nuget packages and the Oracle providers will get packaged with out application:
			1. Oracle.ManagedDataAccess							- if only ADO.NET is needed, then this is enought
			2. Oracle.ManagedDataAccess.EntityFramework			- if we want to use Oracle with EntityFramework we will need this one as well
	5. If the target framework of some projects inside a solution differs the entry project's target version wins at runtime.
	6. This situation is the same with App.config/Web.config files: the settings defined in the entry project wins.
		So for example the <connectionStrings>, <system.serviceModel>, etc. all comes from the entry project at runtime.
		The designer however uses the settings defined in the corresponding project.
	
		
applicationhost.config:

	IIS: 
		ApplicationHost.config is the root file of the IIS 7.0 configuration system. It includes definitions of all sites, applications, virtual directories, and application pools, as well as global defaults for the Web server settings. It is in the following location: %windir%\system32\inetsrv\config.
		
			The following snippet shows how to chage the application path from the root "/" to "/Admin".
			- A new <application> node must be set and the root one must not be deleted but point to an empty folder instead.
		
			<sites>
				<site name="Admin-Site" id="2">
					<application path="/" applicationPool="Clr4IntegratedAppPool">
						<virtualDirectory path="/" physicalPath="C:\Users\pkongyik\Documents\My Web Sites\Empty folder" />
					</application>
					<application path="/Admin" applicationPool="Clr4IntegratedAppPool">
						<virtualDirectory path="/" physicalPath="C:\Projects\CemtPalyazat\src\Admin" />
					</application>
					<bindings>
						<binding protocol="https" bindingInformation="*:44317:localhost" />
						<binding protocol="http" bindingInformation="*:60435:localhost" />
					</bindings>
				</site>
			</sites>
			
			
		Another example:
		
			- application path is set to the root "/"
			
			<site name="WebApplication1" id="2">
				<application path="/" applicationPool="Clr4IntegratedAppPool">
					<virtualDirectory path="/" physicalPath="c:\users\petit\onedrive\dokumentumok\visual studio 2017\Projects\WebApplication1\WebApplication1" />
				</application>
				<bindings>
					<binding protocol="https" bindingInformation="*:44350:localhost" />
                    <binding protocol="http" bindingInformation="*:13000:localhost" />
				</bindings>
			</site>
		
			- application path is set to "/pet":
		
			<site name="WebApplication1" id="2">
				<application path="/" applicationPool="Clr4IntegratedAppPool">
					<virtualDirectory path="/" physicalPath="C:\inetpub\empty_folder" />
				</application>
				<application path="/pet" applicationPool="Clr4IntegratedAppPool">
					<virtualDirectory path="/" physicalPath="c:\users\petit\onedrive\dokumentumok\visual studio 2017\Projects\WebApplication1\WebApplication1" />
				</application>
				<bindings>
					<binding protocol="https" bindingInformation="*:44350:localhost" />
					<binding protocol="http" bindingInformation="*:13000:localhost" />
				</bindings>
			</site>
	
	Client application directory: 
		The ApplicationName.config file contains settings for a Windows client application (not a Web application).
	
	
web.config:

	Web site: 
		The Web.config file for a specific Web site contains settings that apply to the Web site and inherit downward through all of the ASP.NET applications and subdirectories of the site.
	
	ASP.NET application root directory:
		The Web.config file for a specific ASP.NET application is located in the root directory of the application and contains settings that apply to the Web application and inherit downward through all of the subdirectories in its branch.
	
	ASP.NET application subdirectory:
		The Web.config file for an application subdirectory contains settings that apply to this subdirectory and inherit downward through all of the subdirectories in its branch.
		

Dump files, what assemblies are loaded in runtime:
	Place a breakpoint somewhere:
		Debug --> Windows --> Modules: we can check the loaded managed assmeblies here
		Debug --> Save Dump As... we can save a dump file of the current state of the memory then load this dumpfile back into Visual Studio. This time we will see even the unmanaged native libraries that got loaded.
	
	
Sysinternals, Resource monitor

	Download the Sysinternals: google "Windows Sysinternals download" --> Sysinternals Suite
		This contains a lot of system utilities, even the Process monitor
		
	Process Explorer (procexp64.exe): considered to be a more advanced form of the Windows Task Manager
		we can find out which file is being held by which process
		Find --> Find Handle or DLL...
		
	Process monitor (Procmon.exe):
	
	TcpView (Tcpview.exe)
		lets us find out which process uses which port
		
	Resource monitor:
		Task Mananger --> Performance --> Open Resource Monitor
		Network tab --> Listening Ports: just like with TcpView we can see which ports are being used by which application
			Moreover, this even show us whether the port is allowed in our firewall (Firewall Status column)



.NET Standard:

	If you're reading this post, you have hopefully already heard of .NET Standard. This is acts as an interface to .NET Platforms, and aims to define a unified set of APIs that those platforms must implement. 
	It is the spiritual successor to PCLs (Portable Class Library), and allows you to target .NET Framework, .NET Core, and other .NET platforms with the same library code base.

	The NETStandard.Library metapackage references a set of NuGet packages that define the .NET Standard library. Like the Microsoft.AspNetCore package from my last post, 
	the package does not contain dlls itself, but rather references to a number of other packages, hence the name metapackage. 
	Depending on the target platform of your project, different packages will be added to the project, in line with the appropriate version of .NET Standard the platform implements.
	
	
	NET Standard isn't a runtime. It's not something you can install. It's not an "instance of .NET."  .NET Standard is an interface - a versioned list of APIs that you can call. Each newer version of .NET Standard adds more APIs but leaves older platforms/operating systems behind.

	The runtimes then implement this standard. If someone comes out with a new .NET that runs on a device I've never heard of, BUT it "implements .NET Standard" then I just learned I can write code for it. I can even use my existing .NET Standard libraries.
	
	.NET Standard isn't a runtime or a platform. It's not an operating system choice. .NET Standard is a bunch of APIs.
	
	.NET Standard is what you target for your libraries, and the apps that USE your library target a platform.

	
Reference assmeblies:

	 The reference dlls just define the various APIs that these platforms (.NET Framework, .NET Core, Mono, etc) must expose for a given version of .NET Standard.
	 The classes have literally empty method bodies. It will be decided in runtime which implementation will get used.
	 
	 These placeholder assemblies are a key part of the the .NET Standard infrastructure. They provide concrete APIs against which you can compile your projects, 
	 without tying you to a specific implementation (i.e. .NET Framework or .NET Core).
	 
	 
.NET Core:
	
	The runtime is made up of:
		- CoreCLR: the Common Language Runtime for .NET Core, takes the IL generated by the compiler and translates it into code your CPU can understand
		- CoreFX: the .NET Core Framework, containing pretty much everything in the System. namespace. This is the part that is growing massively between .NET Core (and Standard) 1.x and 2.x
		- Roslyn: the .NET compiler platform
		- libuv: the async I/O library that Kestrel (ASP.NET Core's server) runs
	The others:
		- core-setup: build tools to pull in all of the above and combine it into the .NET Core Runtime
		- CLI: the .NET Command Line Interface, so you can dotnet whatever as part of the SDK


	.NET Core 2.0:
	
		Runtime Store
			.NET Core 2.0 brings a new feature called the Runtime Store. This essentially lets you pre-install packages on a machine, in a central location, so you don't have to include them in the publish output of your individual apps.

			You can think of the Runtime Store as a Global Assembly Cache (GAC) for .NET Core. As well serving as a central location for packages, it can also ngen the libraries so they don't have to be jit-ed by your application, which improves startup times for your app.

		Asp.Net Core 2.0

			The Microsoft.AspNetCore.All metapackage includes every package released by Microsoft as part of ASP.NET Core. This has a number of benefits:
				- It reduces the package version management burden
				- It reduces the number of packages that need to be published with the app
					- because now Asp.Net Core 2.0 is sort of "part" of .Net Core 2.0 - Net Core 2.0 installs it
					- still not everything gets packaged when publishing the framework along with your app: some new mechanism excludes libraries that you do not use
				- It makes it easy to use the core packages without having to add them to the solution explicitly
				
			The AspNetCore.All package is included in .NET Core 2.0’s Runtime Store, and is compiled to native code, rather than IL. This means that all of the libraries included in the AspNetCore.All package are pre-compiled as native binaries for the Operating Systems that .NET Core 2.0 supports.
			
		Important interfaces:
			- IConfiguration
			- ILogger
			- ILoggerFactory
			- IHostingEnvironment
			- IHostedService:
				- If you register (with the DI container) an IHostedService then ASP.NET Core will call the Start() and Stop() methods of your type during application start and stop respectively.
			-IHostingStartup
				- The IHostingStartup interface defines a single method: void Configure(IWebHostBuilder builder);. This method is called while the WebHost is being built in the Program.cs of your ASP.NET Core application and allows code to setup anything that can be configured on a WebHostBuidler, including default services and loggers which is how Application Insights works.
				- ASP.NET Core will execute any IHostingStartup implementations in the applications assembly as well as any that are listed in an Environment Variable called ASPNETCORE_HOSTINGSTARTUPASSEMBLIES.
				
		Tag helpers:
			- Tag Helpers enable server-side code to participate in creating and rendering HTML elements in Razor files.
			- Usage:
				[HtmlTargetElement("email")]									// <email></email>
				[HtmlTargetElement(Attributes ="myEmail")]						// <div myEmail></div>
				[HtmlTargetElement("spec-email", Attributes = "veryEmail")]	// <spec-email veryEmail></spec-email>
				public class EmailVoidTagHelper : TagHelper {}
				
				between the [HtmlTargetElement] attributes there is OR relation, while the "Tag" and "Attributes" properties are in AND relation.
				
			- Tag Helper usage explicit: @tagHelperPrefix - to restrict usage of tag helpers
				- in Views/_ViewImports.cshtml: @tagHelperPrefix th:
				- In the code image above the Tag Helper prefix is set to "th:" --> so only those elements using the prefix "th:" support Tag Helpers
					- <th:label asp-for="Password"></th:label> 	--> works
					- <label asp-for="Password"></label			--> won't have any effect
			
		ViewComponents:
			- instead of Html child actions
			- can be used as tag helpers: <vc:priority-list max-priority="2" is-done="false"></vc:priority-list>
		
		RazorPages:
			- built on top of MVC - it is MVC
			- the PageModel is kind of like a ViewModel
				- RazorPages is like MVVM pattern
				- the PageModel is not just a POCO, but the view can bind methods to it
					- GET, POST, PUT, DELETE
				- [BindProperty] - new property in Asp.Net Core 2.0 and works in PageModels AND even in Controllers!
					[BindProperty]
					public Customer Customer { get; set; }
					
					but this old machanism (approach) from Controllers also works:
					public void OnPost(Customer customer) {...}
					
					In case of a successful Post, the pattern that should be used is Post-Redirect-Get:
						return RedirectToPage("Index");		// goes to the Index page of the current folder
						return RedirectToPage("./Index");	// the same as above
						return RedirectToPage("/Index");	// goes to the Index page in the root (Pages folder)
						
			public async Task<IActionResult> OnPostAsync()
			{
				if(!ModelState.IsValid)
				{
					return Page();
				}
				_db.Customers.Add(customer);
				await _db.SaveChanges();
				
				return RedirectToPage("Index");
			}
			
			- TempData: instead of doing this.TempData in the PageModel we can do this instead:
				- [TempData]	- the cookie gets generated specially for the current user, so we do not have to worry about another user reads it first.
				  public string Message { get; set; }
				- this approuch stays in the TempData for not just one request, but until it is read. Then the framework automatically deletes it.
				- works in Controllers as well
				- before TempData was stored in the Session, but now the default TempData provider is Cookies! So a cookie is created and deleted right after the stored TempData gets read.
				
			-	<form method="post">
					...
					<button asp-page-handler="Delete">Delete</button>
					<button asp-page-handler="Send">Send</button>
				</form>
				
				asp-page-handler: changes the form's defult action (which would be an "OnPost" method) to the one specified: well actually it will map to OnPostDelete and OnPostSend. The "Async" suffix is optional.
								  This way we do not have to wrap each button into a new <form> tag.
								  
					<button asp-page-handler="Send" asp-route-id="@Customer.Id">Send</button>
					public async Task OnPostSendAsync(int id) {...}
						But the url becomes like /Customers?id=12&handler=Send
						Easy to change: in the cshtml: @page "{id:int?}/{handler?}"	- "?" means optional
						Now the url becomes: /Customers/12/Send
								  
				For controller actions to be mapped:
					<button asp-controller="Customers" asp-action="Delete">Delete</button>
					
			- Action method resolution: - can be changed by 2 lines of code btw
				1. Look for method the start with "On"
				2. Look for the current HTTP verb after "On"
				3. If there is a handler specified look for it after the verb
				4. Look for "Async" specified optionally. And that's it.
				
			- To add additional routes for certain pages:
				services.AddMvc()
					.AddRazorPagesOptions(options =>
				{
					options.Conventions.AddPageRoute("Customers/Index", "AllCustomers");
				});
				
			- Filters: there is a new filter type: IPageFilter and IAsyncPageFilter
				[Authorize]			// can be added to actions as well (OnXXX)
				public class NewModel : PageModel {...}
				
				- PagesFilter target pages
					public class LoggingFilter : IPageFilter {...}
					To use this: services.AddMvc().AddMvcOptions(options => options.Filters.Add<LoggingFilter>())
		
		Logging:
			- structued logging: 
				- basically involves associating key-value pairs with each log entry, instead of a simple string "message".
				- Un unstructured message stored as a structured log would essentially be stored as a JSON object making it easily searchable, as something like:
					unstructured: 
						info: Microsoft.AspNetCore.Hosting.Internal.WebHost[1]  
						Request starting HTTP/1.1 GET http://localhost:51919/
					structued:
						{
							"eventLevel" : "Information",
							"category" : "Microsoft.AspNetCore.Hosting.Internal.WebHost",
							"eventId" : 1,
							"message" : "Request starting HTTP/1.1 GET http://localhost:51919/",
							"protocol" : "HTTP/1.1",
							"method" : "GET",
							"url" : "http://localhost:51919/"
						}
				- we can add arbitrary data to any log messages by creating a scope via: "_logger.BeginScope<T>(T state)"
					- but if there is an exception, logging in the catch block would not contain these data
					- To work around this: there is a lesser known "feature" of exception filters that we can make of here - the code in an exception filter runs in the same context in which the original exception occurred - the stack in unharmed, and is only dumped if the exception filter evaluates to true.
					
						_logger.LogInformation("Before");
						try
						{
							using (_logger.BeginScope("Some name"))
							using (_logger.BeginScope(42))
							using (_logger.BeginScope("Formatted {WithValue}", 12345))
							using (_logger.BeginScope(new Dictionary<string, object> { ["ViaDictionary"] = 100 }))
							{
								throw new Exception("Oops, something went wrong!");
								_logger.LogInformation("Hello from the Index!");
								_logger.LogDebug("Hello is done");
							}

							_logger.LogInformation("After");

							return new string[] { "value1", "value2" };
						}
						catch (Exception ex) when (LogError(ex))
						{
							return new string[] { };
						}
						
						bool LogError(Exception ex)
						{
							// this will contain the "ViaDictionary", "WithValue", ... scopes
							_logger.LogError(ex, "An unexpected exception occured");
							return true;
						}
		
		

Date handling

	DateTime vs DateTimeOffset
	
		Use DateTimeOffset is timezone information is needed.
	
		A DateTime value defines a particular date and time. Starting with version 2.0 of the .NET Framework, it includes a Kind property that provides limited information about the time zone to which that date and time belongs. 
		The DateTimeKind value returned by the Kind property indicates whether the DateTime value represents the local time (DateTimeKind.Local), Coordinated Universal Time (UTC) (DateTimeKind.Utc), or an unspecified time (DateTimeKind.Unspecified).
		
		The DateTimeOffset structure represents a date and time value, together with an offset that indicates how much that value differs from UTC. Thus, the value always unambiguously identifies a single point in time.
	

	
MSBuild
	
	.Target files: https://msdn.microsoft.com/en-us/library/ms164312.aspx
		MSBuild includes several .targets files that contain items, properties, targets, and tasks for common scenarios. These files are automatically imported into most Visual Studio project files to simplify maintenance and readability.
		Projects typically import one or more .targets files to define their build process. For example a Visual C# project created by Visual Studio will import Microsoft.CSharp.targets which imports Microsoft.Common.targets. The Visual C# project itself will define the items and properties specific to that project, but the standard build rules for a Visual C# project are defined in the imported .targets files.
		
	ItemGroup element: https://msdn.microsoft.com/en-us/library/646dk05y.aspx
		Contains a set of user-defined Item elements. Every item used in a MSBuild project must be specified as a child of an ItemGroup element.
		
	PropertyGroup element: https://msdn.microsoft.com/en-us/library/t4w159bs.aspx
		Contains a set of user-defined Property elements. Every Property element used in an MSBuild project must be a child of a PropertyGroup element.
		
	VS2015 uses "dotnet.exe" whereas VS2017 uses MSBuild.
		MSBuild.exe runs on .NET Framework
		dotnet msbuild runs on .NET Core
		
		If you update the dotnet cli, VS2017 won't benefit from it because it does not use it. You need to update VS2017 as well.
		
dotnet cli:
	dotnet --help

	1. create a new project: dotnet new ...
	2. dotnet restore
	3. dotnet run --> and the app runs
	
	3. dotnet build --> creates the dlls in the bin\Debug\netcoreapp1.1 folder
	
	3. dotnet clean --> cleans the bin\Debug\netcoreapp1.1 folder
	
	3. dotnet publish --> packages the application that can be copied to iis or run from the cli (location is bin\Debug\netcoreapp1.1\publish)
	4. dotnet {myApplication.dll} --> runs the packaged application (after cd-ing into the bin\Debug\netcoreapp1.1\publish folder)
	
Docker with Asp.Net Core
	- download docker for windows
	- keep using Linux containers! do not switch to Windows containers (there is a bug and the app from VS just won't start)
	- when pressing F5 is VS:
		- VS uses the linux container and deploys everything there
		- builds the Dockerfile on the MobyLinuxVM.vhdx and the image gets pulled into docker (docker images will display the newly created image)
			- the name of the image is located in the docker-compose project's "docker-compose.yml" file
		- creates a container from the image (docker run [image_name])
		- starts the container (docker start [container_id])
	- when shutting down the app from VS
		- the container keeps running
			docker stop [container_id] - to stop the container
			docker rm [container_id] - to remove the container
			docker rmi [image_id] - to remove the image
			
			
launchsettings.json:

	{
	  "iisSettings": {
		"windowsAuthentication": false,
		"anonymousAuthentication": true,
		"iisExpress": {
		  "applicationUrl": "http://localhost:54435/",
		  "sslPort": 0
		}
	  },
	  "profiles": {
		"IIS Express": {
		  "commandName": "IISExpress",
		  "launchBrowser": true,
		  "environmentVariables": {
			"ASPNETCORE_ENVIRONMENT": "Development"
		  }
		},
		"WebAppDocker": {
		  "commandName": "Project",
		  "launchBrowser": true,
		  "environmentVariables": {
			"ASPNETCORE_ENVIRONMENT": "Development"
		  },
		  "applicationUrl": "http://localhost:54436"
		}
	  }
	}

	The "WebAppDocker" profile tell VS to run the project (i.e. via dotnet.exe) instead of starting up IIS Express and deploy the app to it.

	
.csproj magic:

	<Project Sdk="Microsoft.NET.Sdk">

		<PropertyGroup>
			<TargetFramework>net462</TargetFramework>
			<RunXunitTests Condition="'$(RunXunitTests)' == 'Release'">true</RunXunitTests>
		</PropertyGroup>
	  
		// This way "RunXunitTests" task will get executed only if the "Release" is true
		
		<PropertyGroup>
			<TargetFramework>net462</TargetFramework>
			<OwnProp>true></OwnProp>
			<RunXunitTests Condition="'$(RunXunitTests)' == '$(OwnProp)'">false</RunXunitTests>
			<RunXunitTests Condition="'$(RunXunitTests)' == '$(TargetFramework)'">net462</RunXunitTests>
	  </PropertyGroup>
	  
		// The same as above, but checking a custom defined property this time
	  
	</Project>


32-bit vs 64-bit compilation:

	You compile your code to IL which gets executed and compiled to machine code during runtime, this is what's called JIT.
	The JIT is one aspect of the CLR (Common Language Runtime).
	Specifically it is the part responsible for changing CIL/MSIL (hereafter called IL) produced by the original language's compiler (csc.exe for Microsoft c# for example) into machine code native to the current processor (and architecture that it exposes in the current process, for example 32/64-bit). If the assembly in question was ngen'd (AOT - Ahead of time compilation) then the the JIT process is completely unnecessary and the CLR will run this code just fine without it.
	
	If the app contains only managed code, stick with the "Any CPU" solution build configuration.
	
	However, it the app has some libraries that are native (written in unmanaged code - for example the oracle driver), the entrypoint project's platform target may need to be set accordingly
		- typically to 32-bit on a 64-bit OS - because if the native code is 32-bit it tends to run only inside 32-bit applications
		- does no need to be set to 64-bit because if the OS is 64-bit then "Any CPU" compilation will result in the JIT compile 64-bit native code from the IL
		
		(- 64-bit applications can run only on 64-bit OS)
		(- 32-bit apps can run on both 64-bit and 32-bit OS)
	
		So the JIT compiles our code into native 32/64-bit executable code depending on the current processor.
		
		So, Oracle unmanaged driver: because it is written in unamanged (C++) code its compiled dll contains native code already. 
		It is not IL code --> no JIT is required --> it can run on the current processing immediately (theoritically).
			--> 64-bit processor needs the 64-bit version of the unmanaged driver, whereas 32-bit processor needs the 32-bit compiled version.
	
	C# Code > C# Compiler > IL > .NET Runtime > JIT Compiler > Machinecode > Execution
	
	
	
SQL Server:

	:on error exit
	:SETVAR databaseName "Ekaer"

	USE [master]
	
	CREATE LOGIN [NT SERVICE\EkaerService] FROM WINDOWS WITH DEFAULT_DATABASE=[master]	-- this creates a user under "INSTANCE/Security/Logins" that can login to the db. 
	GO
	
	USE [$(databaseName)]															-- using the "Ekaer" db
	GO
	CREATE USER [NT SERVICE\EkaerService] FOR LOGIN [NT SERVICE\EkaerService]		-- add the user to "INSTANCE/Databases/Ekaer/Security/Users", so the user can access the database
	GO
	ALTER ROLE [db_datareader] ADD MEMBER [NT SERVICE\EkaerService]					-- adding the necessary roles: equivalent to "User Mapping" if doing: right clik on the "NT SERVICE\EkaerService" --> Properties --> User Mapping
	GO
	ALTER ROLE [db_datawriter] ADD MEMBER [NT SERVICE\EkaerService]
	GO
	
	
Threading:

	- ExecutionContext:
	
		--ExecutionContext is actually just a container for other contexts. ExecutionContext is all about “ambient” information, meaning that it stores data relevant to the current environment or “context” in which you’re running.  In many systems, such ambient information is maintained in thread-local storage (TLS), such as in a ThreadStatic field or in a ThreadLocal<T>. 
		For example, one of the contexts contained by ExecutionContext is SecurityContext, which maintains information like the current “principal” and information about code access security (CAS) denies and permits.
		
		// ambient state captured into ec 
		ExecutionContext ec = ExecutionContext.Capture();
		
		ExecutionContext.Run(ec, delegate 
		{ 
			… // code here will see ec’s state as ambient 
		}, null);
		
	- SynchronizationContext:
	
		--SynchronizationContext is just an abstraction, one that represents a particular environment you want to do some work in.  As an example of such an environment, Windows Forms apps have a UI thread (while it’s possible for there to be multiple, for the purposes of this discussion it doesn’t matter), which is where any work that needs to use UI controls needs to happen.  For cases where you’re running code on a ThreadPool thread and you need to marshal work back to the UI so that this work can muck with UI controls, Windows Forms provides the Control.BeginInvoke method.  You give a delegate to a Control’s BeginInvoke method, and that delegate will be invoked back on the thread with which that control is associated.
		
		So, if I’m writing a component that needs to schedule some work to the ThreadPool and then continue with some work back on the UI thread, I can code my component to use Control.BeginInvoke.  But now what if I decide I want to use my component in a WPF app? WPF has the same UI thread constraint that Windows Forms has, but it has a different mechanism for marshaling back to the UI thread: rather than using Control.BeginInvoke on a control associated with the right thread, you use Dispatcher.BeginInvoke (or InvokeAsync) on the Dispatcher instance associated with the right thread. 
		
		We now have two different APIs for achieving the same basic operation, so how do I write my component to be agnostic of the UI framework?  By using SynchronizationContext.  SynchronizationContext provides a virtual Post method; this method simply takes a delegate and runs it wherever, whenever, and however the SynchronizationContext implementation deems fit.  Windows Forms provides the WindowsFormSynchronizationContext type which overrides Post to call Control.BeginInvoke.  WPF provides the DispatcherSynchronizationContext type which overrides Post to call Dispatcher.BeginInvoke.  And so on.  As such, I can now code my component to use SynchronizationContext instead of tying it to a specific framework.
		
		var sc = SynchronizationContext.Current; 
		ThreadPool.QueueUserWorkItem(delegate 
		{ 
			… // do work on ThreadPool 
			sc.Post(delegate 
			{ 
				… // do work on the original context 
			}, null); 
	   }); 
	   
	When you flow ExecutionContext, you’re capturing the state from one thread and then restoring that state such that it’s ambient during the supplied delegate’s execution.  That’s not what happens when you capture and use a SynchronizationContext.  The capturing part is the same, in that you’re grabbing data from the current thread, but you then use that state differently.  Rather than making that state current during the invocation of the delegate, with SynchronizationContext.Post you’re simply using that captured state to invoke the delegate.  Where and when and how that delegate runs is completely up to the implementation of the Post method.
	
	
	Async-await: 
	
		--The framework automatically flows the ExecutionContext. It cannot be turned off, this is by design.
		On the other hand, posting back to the SynchronizationContext.Current can be suppressed via task.ConfigureAwait(false).
		Note that while ConfigureAwait provides explicit, await-related programming model support for changing behavior related to SynchronizationContext, there is no await-related programming model support for suppressing ExecutionContext flow.  This is on purpose.
	
		- The framework support behind the async and await keywords automatically interacts with both ExecutionContext and SynchronizationContext.
		ExecutionContext needs to flow from the code issuing the await through to the continuation delegate’s execution.  That’s handled automatically by the Framework.  When the async method is about to suspend, the infrastructure captures an ExecutionContext. This is what enables the important “ambient” information represented by ExecutionContext to flow across awaits.
		
		- The Framework also has support for SynchronizationContext.  The aforementioned support for ExecutionContext is built into the “builders” that represent async methods (e.g. System.Runtime.CompilerServices.AsyncTaskMethodBuilder), and these builders ensure that ExecutionContext is flowed across await points regardless of what kind of awaitable is being used.  In contrast, support for SynchronizationContext is built into the support for awaiting Task and Task<TResult>, specifically.  Custom awaiters could add similar logic themselves, but they don’t get it automatically; that’s by design, as being able to customize when and how the continuation gets invoked is part of why custom awaiters are useful.
		
		- When you await a task, by default the awaiter will capture the current SynchronizationContext, and if there was one, when the task completes it’ll Post the supplied continuation delegate back to that context, rather than running the delegate on whatever thread the task completed or rather than scheduling it to run on the ThreadPool. 
		If a developer doesn’t want this marshaling behavior, it can be controlled by changing the awaitable/awaiter that’s used.  Whereas this behavior is always employed when you await a Task or Task<TResult>, you can instead await the result of calling task.ConfigureAwait(…).  The ConfigureAwait method returns an awaitable that enables this default marshaling behavior to be suppressed.  Whether it’s suppressed is controlled by a Boolean passed to the ConfigureAwait method.  If continueOnCapturedContext is true, then you get the default behavior; if it’s false, the awaiter doesn’t check for a SynchronizationContext, pretending as if there wasn’t one. (Note that when the awaited task completes, regardless of ConfigureAwait, the runtime may check the context that’s current on the resuming thread to determine whether it’s ok to synchronously run the continuation there or whether the continuation must be scheduled asynchronously from that point.)
		
		- Note that while ConfigureAwait provides explicit, await-related programming model support for changing behavior related to SynchronizationContext, there is no await-related programming model support for suppressing ExecutionContext flow.  This is on purpose.  ExecutionContext is not something developers writing async code should need to worry about; it’s infrastructure level support that helps to simulate synchronous semantics (i.e. TLS) in an asynchronous world.  Most folks can and should completely ignore that it’s there (and should avoid using the ExecutionContext.SuppressFlow method unless they really know what you’re doing).  In contrast, where code runs is something developers should be cognizant of, and thus SynchronizationContext rises to level of something that does deserve explicit programming model support.  (In fact, as I’ve stated in other posts, most library implementers should consider using ConfigureAwait(false) on every await of a task.)
		
	Isn’t SynchronizationContext part of ExecutionContext?
	
		- The main thing I glossed over is that of all the contexts ExecutionContext is capable of flowing (e.g. SecurityContext, HostExecutionContext, CallContext, etc.), SynchronizationContext is actually one of them.  This is, I personally believe, a mistake in API design, one that’s caused a few problems since it was instituted in .NET many versions ago.  Nevertheless, it’s the design we have and have had for a long time, and changing it now would be a breaking change.

		- When you call the public ExecutionContext.Capture() method, that checks for a current SynchronizationContext, and if there is one, it stores that into the returned ExecutionContext instance.  Then, when the public ExecutionContext.Run method is used, that captured SynchronizationContext is restored as Current during the execution of the supplied delegate.
		
		
	Await, SynchronizationContext, and Console Apps
	
		--SynchronizationContext: 
		
			- WPF, Windows Forms, Asp.Net has their own implementation (deriving from System.Threading.SynchronizationContext)
			- Console apps, Asp.Net Core (afterall this is a console app as well) has no SynchronizationContext: SynchronizationContext.Current is null!
				--> That means that if you invoke an asynchronous method in your console app, unless you do something special, your asynchronous methods will not have thread affinity: 
					the continuations within those asynchronous methods could end up running “anywhere.”
				
					Anywhere means:
						- it’ll either end up running on the same thread that completed the awaited task
						- or it’ll end up running in the ThreadPool.
			

		- When I discuss the new async language features of C# and Visual Basic, one of the attributes I ascribe to the await keyword is that it “tries to bring you back to where you were.” For example, if you use await on the UI thread of your WPF application, the code that comes after the await completes should run back on that same UI thread.
		
		- There are several mechanisms that are used by the async/await infrastructure under the covers to make this marshaling work: SynchronizationContext and TaskScheduler. While the transformation is much more complicated than what I’m about to show, logically you can think of the following code:
		
			await FooAsync();
			RestOfMethod();
		as being similar in nature to this:
			var t = FooAsync();
			var currentContext = SynchronizationContext.Current;
			t.ContinueWith(delegate
			{
				if (currentContext == null)
					RestOfMethod();
				else
					currentContext.Post(delegate { RestOfMethod(); }, null);
			}, TaskScheduler.Current);
			
		- Both SynchronizationContext and TaskScheduler are abstractions that represent a “scheduler”, something that you give some work to, and it determines when and where to run that work. There are many different forms of schedulers. For example, the ThreadPool is a scheduler: you call ThreadPool.QueueUserWorkItem to supply a delegate to run, that delegate gets queued, and one of the ThreadPool’s threads eventually picks up and runs that delegate. Your user interface also has a scheduler: the message pump. A dedicated thread sits in a loop, monitoring a queue of messages and processing each; that loop typically processes messages like mouse events or keyboard events or paint events, but in many frameworks you can also explicitly hand it work to do, e.g. the Control.BeginInvoke method in Windows Forms, or the Dispatcher.BeginInvoke method in WPF.
		
		- SynchronizationContext, then, is just an abstract class that can be used to represent such a scheduler. The base class exposes several virtual methods, but we’ll focus on just one: Post. Post accepts a delegate, and the implementation of Post gets to decide when and where to run that delegate.
		
		- The default implementation of SynchronizationContext.Post just turns around and passes it off to the ThreadPool via QueueUserWorkItem. But frameworks can derive their own context from SynchronizationContext and override the Post method to be more appropriate to the scheduler being represented. In the case of Windows Forms, for example, the WindowsFormsSynchronizationContext implements Post to pass the delegate off to Control.BeginInvoke. For DispatcherSynchronizationContext in WPF, it calls to Dispatcher.BeginInvoke. And so on.
		
		- That’s how await “brings you back to where you were.” It asks for the SynchronizationContext that’s representing the current environment, and then when the await completes, the continuation is posted back to that context. It’s up to the implementation of the captured context to run the delegate in the right place, e.g. in the case of a UI app, that means running the delegate on the UI thread.
		
		- This explanation also helps to highlight what happens if the environment didn’t set a SynchronizationContext onto the current thread (and if there’s not special TaskScheduler, as there isn’t in this case). If the context comes back as null, then the continuation could run “anywhere”. I put anywhere in quotes because obviously the continuation can’t run “anywhere,” but logically you can think of it like that… 
			- it’ll either end up running on the same thread that completed the awaited task
			- or it’ll end up running in the ThreadPool.
			
		- All of the UI application types you can create in Visual Studio will end up having a special SynchronizationContext published on the UI thread. Windows Forms, Windows Presentation Foundation, Metro style apps… they all have one. But there’s one common kind of application that doesn’t have a SynchronizationContext: console apps
			- When your console application’s Main method is invoked, SynchronizationContext.Current will return null. That means that if you invoke an asynchronous method in your console app, unless you do something special, your asynchronous methods will not have thread affinity: the continuations within those asynchronous methods could end up running “anywhere.”